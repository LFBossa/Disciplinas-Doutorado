\documentclass{beamer}
\usepackage[utf8]{inputenc}
\usepackage[brazil]{babel}
\usepackage{xcolor}
\usepackage{tikz}
\usetikzlibrary{positioning,calc}
\usepackage{graphicx}
\usepackage{cite}
\usepackage{hyperref}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{listings}
\usepackage{enumerate}
\usepackage{fontawesome}
\usepackage{ulem}

%https://github.com/battlesnake/neural
%
\usepackage{neuralnetwork}
%https://pt.overleaf.com/latex/templates/template-departamento-de-mtm-ufsc/jxjxqttwjrws
\usetheme{mtmufsc} %%%%%%%%Use this template
\renewcommand{\qedsymbol}{$\blacksquare$}
% This is a beamer template inspired by unofficial Oxford University Beamer Template, made by Clara Eleonore Pavillet.
\title{Teoria Efetiva de Redes Lineares Profundas na Inicialização}
\author{Luiz Fernando Bossa}
\date{\today}
\institute{Universidade Federal de Santa Catarina}


\newcommand{\PP}{\mathbb{P}}
\newcommand{\EE}{\mathbb{E}}
\newcommand{\RR}{\mathbb{R}}
\DeclareMathOperator{\Cov}{Cov}
\DeclareMathOperator{\Var}{Var}
\DeclareMathOperator{\Wick}{Wick}
\newcommand{\vX}{\vec{X}}
\newcommand{\vY}{\vec{Y}}
\newcommand{\vmu}{\vec{\mu}}
\newcommand{\WW}{\mathcal{W}}
\newcommand{\aaA}{\alpha}
\newcommand{\aaB}{\beta} 
\newcommand{\OO}{\mathcal{O}}
\def\mi#1{{\,\widehat{#1}}}
\def\mj#1{\underline{#1}}
\def\eell{{(\ell)}}
\def\eellum{{(\ell+1)}}
\def\wickquatro{\delta_{\mi1\mi2}\delta_{\mi3\mi4} + \delta_{\mi1\mi3}\delta_{\mi2\mi4}+  \delta_{\mi1\mi4}\delta_{\mi2\mi3}}
\def\ddelta#1#2{\delta_{\mi{#1}\mi{#2}}}



\begin{document}

{\setbeamertemplate{footline}{} 
\frame{\titlepage}}
\frame{\tableofcontents}


\section{Notações e Definições}    
%Sempre que iniciar uma nova sessão, você pode fazer um slide de transição com o índice.
\begin{frame}
\tableofcontents[currentsection]
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
%A partir daqui, faça seus slides%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}{\S 2.1 Aproximação de Funções}
Uma rede neural com $L$ camadas, cada camada tendo $n_\ell$ neurônios e dados de entrada $x_\alpha$ é dada por:
\begin{align*}
	z^{(1)} &= W^{(1)} x_\alpha + b^{(1)}  \\\tag{2.5}\label{eq:NN}
	z^\eellum &= W^\eellum \sigma\big(z^\eell\big) + b^\eell, \qquad \ell = 1, \ldots, L-1 \\
\end{align*}
\begin{itemize}
	\item $z^\eell$ é um vetor de tamanho $n_\ell$ 
	\item $W^\eell$ é uma matriz de tamanho $n_\ell \times n_{\ell-1}$
\end{itemize}

%Pré-ativação na camada $\ell+1$ é dada pela aplicação da matriz de pesos $W^{(\ell+1)}$ e a soma do vetor de bias $b^{(\ell)}$ na ativação da camada $\ell$.

\end{frame}
 
\begin{frame}{\S 2.3 Aprendizado em conjunto}
	\framesubtitle{Initialization distribuitions}
	Distribuição inicial: médias zero e variâncias dadas por
	\begin{align*}
		\EE\left(b^\eell_{i}b^\eell_j\right) &= \delta_{ij}C_b^\eell  \tag{2.19}\\
		\EE\left(W^\eell_{ij}W^\eell_{kl}\right) &= \delta_{ik}\delta_{jl}\frac{C_W^\eell}{n_{\ell-1}} \tag{2.20}	
	\end{align*}
	Estamos trabalhando com distribuições unidimensionais.
\end{frame}


\begin{frame}{Minhas observações}
	Para duas variáveis aleatórias $X$ e $Y$ com médias zero, temos 
	$$\Cov(X,Y) = \EE((X-0)(Y-0)) = \EE(XY)$$
	E em particular, 
	$$\Cov(X,X) = \EE(X^2) = \Var(X)$$
\end{frame}

\begin{frame}{Minha notação vetorial}
	Se $A$ é uma matriz, utilizaremos a notação 
	\begin{itemize}
		\item $A_{ij}$ para o elemento da linha $i$ e coluna $j$.
		\item $A_{i*}$ para a linha $i$.	
		\item $A_{*j}$ para a coluna $j$.
		\item O produto interno dos vetores $u$ e $v$ será denotado por $u\cdot v$.
	\end{itemize}
\end{frame}

\begin{frame}{Salada de índices}
	\begin{itemize}
		\item Particularmente eu não gosto de salada de índice, não me cai bem. 
		\item Fiz as seguintes transformações nos índices
		
	\end{itemize}
	\begin{center}
		\begin{tabular}{c c r}
			\hline
			\textbf{Original}  &\textbf{Minha notação} & \textbf{Índices}\\
			\hline
			 $i_1, i_2$ & $i, j$ &  coordenada fixas \\ 
			 $j_1, j_2, j$ & $k, l, \nu$ &  coordenadas variáveis \\		
			 $\alpha_1, \alpha_2$  & $\aaA, \aaB$ & dados de entrada \\
		\end{tabular}		
	\end{center}
	
\end{frame}

\begin{frame}{\S 2.3 Aprendizado em conjunto}	
	Assim, podemos escrever as equações (2.19) e (2.20) como
	\begin{align*}
		(2.19) &= \begin{cases}
		\Cov\left(b^\eell_{i},b^\eell_j\right) = 0, \quad i\neq j\\[1ex]
		\Var\left(b^\eell_{i}\right) = C_b^\eell \\
		\end{cases}  \tag{2.19'}\\[2ex] 
		(2.20) &= \begin{cases}
		\Cov\left(W^\eell_{ij},W^\eell_{kl}\right) = 0, \quad (i,j)\neq (k,l)\\[1ex]
		\Var\left(W^\eell_{ij}\right) = \frac{C_W^\eell}{n_{\ell-1}} \\
		\end{cases} \tag{2.20'}
	\end{align*}
\end{frame}

\begin{frame}{\S 2.3 Aprendizado em conjunto}
	Embora não valha para todas as distribuições\footnote{\href{https://almostsuremath.com/2021/03/24/independence-of-normals/}{Independence of Normals}}, se $X$ e $Y$ são variáveis aleatórias gaussianas, então $X$ e $Y$ são independentes se e somente se $\Cov(X,Y) = 0$.  

	\medskip

	Segue que as $b^\eell_i$ e $W^\eell_{ij}$ são variáveis gaussianas independentes, com médias zero e variâncias dadas por $C_b^\eell$ e $\frac{C_W^\eell}{n_{\ell-1}}$.
\end{frame}

\section{Teoria Efetiva de Redes Lineares Profundas na Inicialização}

\begin{frame}
	\tableofcontents[currentsection]
\end{frame}

\begin{frame}{Roteiro}
	\begin{enumerate}[\S 3.1]
		\item Redes Lineares Profundas
		\item Criticalidade: cálculo do correlator de 2 pontos
		\item Flutuações: cálculo do correlator de 4 pontos
		\item \sout{Caos: cálculo do correlator de 6 pontos}
	\end{enumerate}
	
\end{frame}

\subsection{Redes Lineares Profundas}
\begin{frame}{Redes Lineares Profundas}
	\begin{itemize}
		\item São redes neurais com funções de ativação identidade $\sigma(x) = x$.
		\item Para simplificar a análise, zeramos os vieses $b^\eell \equiv \vec{0}$.
		\item A equação \eqref{eq:NN} se torna
		\begin{align*}
			z^{(1)} &= W^{(1)} x_\alpha \\ 	
			z^{(\ell+1)} &= W^{(\ell+1)}\big(z^\eell\big), \qquad \ell = 1, \ldots, L-1 
		\end{align*}
	\end{itemize}
\end{frame}
\begin{frame}{Redes Lineares Profundas}
	\begin{equation*}\tag{3.2}\label{eq:zele}
		z^\eell_\alpha = W^\eell W^{(\ell-1)}\cdots W^{(1)} x_\alpha
	\end{equation*}
Introduzimos a notação 
	\begin{equation*}\tag{3.3}\label{eq:Wcali}
		\WW^\eell = W^\eell W^{(\ell-1)}\cdots W^{(1)}
	\end{equation*}

Fazemos todas as variâncias constantes e independentes da camada $C_W^\eell \equiv C_W$. 
\end{frame}


\begin{frame}
	\includegraphics{redeneural.pdf}
\end{frame}


\begin{frame}{Objetivos}
	Queremos calcular 
	$$p\big(z^\eell_\alpha\mid \mathcal{D}\big) $$ 
\begin{itemize}
	\item 
	Uma distribuição é completamente determinada pelos seus momentos, que são dados por seus correlatores de M pontos.
\end{itemize}
\end{frame}

\begin{frame}{Esperança}
	\begin{itemize}
		\item Note que pela equação \eqref{eq:zele}, temos que 
		\begin{equation*}\tag{3.2'}\label{eq:zele1}
		z^\eell_{\alpha} = W^\eell z^{(\ell -1)}_\alpha
		\end{equation*}
		\item Podemos calcular a esperança de $z^\eell_{\alpha}$ componente a componente, lembrando que é o produto interno da $i$-ésima linha da matriz $W^\eell$ com o vetor $z^{(\ell -1)}_\alpha$.
	\end{itemize}
\end{frame}
\begin{frame}{Esperança}
	
	\begin{align*}
		\EE\big(z^\eell_{i;\alpha}\big) &= \EE\left(W_{i*}^\eell \cdot z^{(\ell -1)}_\alpha\right) \\% & (\text{coordenada $i$ de  $z^\eell_{\alpha}$})\\
		&= \EE\left(\sum_{j=1}^{n_{\ell-1}} W_{ij}^\eell z^{(\ell -1)}_{j;\alpha}\right) \\% & \text{(abre como somatório)}  \\
		&=\sum_{j=1}^{n_{\ell-1}}\EE\left( W_{ij}^\eell z^{(\ell -1)}_{j;\alpha}\right) \\%& \text{(linearidade da esperança)}\\
		&= \sum_{j=1}^{n_{\ell-1}} \underset{0}{\underbrace{\EE\left(W_{ij}^\eell\right)}} \EE\left(z^{(\ell -1)}_{j;\alpha}\right) = 0 \tag{3.6} \label{eq:media} %& \text{(independencia camadas)}
	\end{align*} 
\end{frame}

\begin{frame}{Momentos ímpares}
	\begin{itemize}
		\item Os autores afirmam que, por um argumento similar, é possível mostrar que os momentos de ordem ímpar serão todos zerados. 
	\end{itemize}
\end{frame}

\subsection{Criticalidade}

\begin{frame}
	\tableofcontents[currentsubsection]
\end{frame}

\begin{frame}{Criticalidade}
	\begin{itemize}
		\item Vamos calcular o correlator de 2 pontos na primeira camada, coordenada a coordenada
	\end{itemize}
		\begin{align*}
			\EE\big(z^{(1)}_{i;\aaA} z^{(1)}_{j;\aaB}\big) &= \EE\left(W^{(1)}_{i*}\cdot x_{\aaA}W^{(1)}_{j*}\cdot x_{\aaB} \right)\\
		&= \EE\left( \left(\sum_{k=1}^{n_0} W^{(1)}_{ik}x_{k;\aaA}\right)
		\left(\sum_{l=1}^{n_0} W^{(1)}_{il}x_{l;\aaA}\right) \right)\\
		&= \EE\left(\sum_{k=1}^{n_0}\sum_{l=1}^{n_0}W^{(1)}_{ik}x_{k;\aaA}W^{(1)}_{il}x_{l;\aaB} \right) \\
		\end{align*}
\end{frame}
\begin{frame}{Correlator camada 1}
	\begin{align*}
		&=\EE\left(\sum_{k=1}^{n_0}\sum_{l=1}^{n_0}W^{(1)}_{ik}x_{k;\aaA}W^{(1)}_{il}x_{l;\aaB} \right) = \sum_{k,l=1}^{n_0} \EE\left(W^{(1)}_{ik}W^{(1)}_{jl}\right) x_{k;\aaA}x_{l;\aaB} \\
		&= \sum_{k,l=1}^{n_0} \delta_{ij}\delta_{kl}\frac{C_W}{n_0} x_{k;\aaA}x_{l;\aaB} =\delta_{ij}\frac{C_W}{n_0} \sum_{k,l=1}^{n_0}\delta_{kl}x_{k;\aaA}x_{l;\aaB} =  ^{\dagger}\\
		&= \delta_{ij}\frac{C_W}{n_0} \sum_{\nu=1}^{n_0} x_{\nu;\aaA}x_{\nu;\aaB} =  \delta_{ij}\frac{C_W}{n_0}  x_{\aaA} \cdot x_{\aaB} \tag{3.8} \label{eq:corrcamada1}
	\end{align*}
	Na passagem $\dagger$, note que as parcelas somem quando $k\neq l$, então fazemos uma mudança de variáveis $\nu = k = l$.
\end{frame}

\begin{frame}{Correlator camada 1}
	Criamos a notação 
	\begin{equation*}\tag{3.9}\label{eq:G0}
		G_{\aaA\aaB}^{(0)} = \frac{1}{n_0} x_{\aaA}\cdot x_{\aaB}
	\end{equation*}
	Assim 
	\begin{equation*}\tag{3.10}\label{eq:correlator1G}
		\EE\big(z^{(1)}_{i;\aaA} z^{(1)}_{j;\aaB}\big) = \delta_{ij}C_WG_{\aaA\aaB}^{(0)}
	\end{equation*}
	\begin{itemize}
		\item Note que no lado direito da equação acima, o único termo que depende das coordenadas $i,j$ é $\delta_{ij}$.
\end{itemize}
\end{frame}

\begin{frame}{Correlator camada $\ell+1$}
	\begin{itemize}
		\item Vamos calcular o correlator de 2 pontos na camada $\ell+1$ de maneira recursiva, utilizando a equação \eqref{eq:zele1}
		\begin{equation*}\tag{3.2'}
			z^\eellum_{\alpha} = W^\eellum z^\eell_\alpha
		\end{equation*}
	\end{itemize}
\end{frame}

\begin{frame}{Correlator camada $\ell + 1$}
	\begin{align*}
		\EE\big(z^\eellum_{i;\aaA} z^\eellum_{j;\aaB}\big) &= 
		\EE\left(W^\eellum_{i*}\cdot z^\eell_{\aaA}W^\eellum_{j*}\cdot z^\eell_{\aaB} \right)  \\
		&=\EE\left( \left(\sum_{k=1}^{n_\ell} W^\eellum_{ik}z^\eell_{k;\aaA}\right)
		\left(\sum_{l=1}^{n_\ell} W^\eellum_{il}z^\eell_{l;\aaA}\right) \right)\\
		&=\sum_{k,l=1}^{n_\ell} \EE\left(W^\eellum_{ik}W^\eellum_{jl}z^\eell_{k;\aaA}z^\eell_{l;\aaB} \right)\\
		&=\sum_{k,l=1}^{n_\ell} \EE\left(W^\eellum_{ik}W^\eellum_{jl}\right) \EE\left(z^\eell_{k;\aaA}z^\eell_{l;\aaB} \right)\\
	\end{align*}
\end{frame}

\begin{frame}{Correlator camada $\ell+1$}
	\begin{align*}
		&=\sum_{k,l=1}^{n_\ell} \EE\left(W^\eellum_{ik}W^\eellum_{jl}\right) \EE\left(z^\eell_{k;\aaA}z^\eell_{l;\aaB} \right)\\
		&=\sum_{k,l=1}^{n_\ell} \delta_{ij}\delta_{kl}\frac{C_W}{n_\ell} \EE\left(z^\eell_{k;\aaA}z^\eell_{l;\aaB} \right) 
		=\delta_{ij}\frac{C_W}{n_\ell}\sum_{k,l=1}^{n_\ell} \delta_{kl} \EE\left(z^\eell_{k;\aaA}z^\eell_{l;\aaB} \right) \\
		&= \delta_{ij}\frac{C_W}{n_\ell} \sum_{\nu=1}^{n_\ell} \EE\left(z^\eell_{\nu;\aaA}z^\eell_{\nu;\aaB} \right) \\
		&= \delta_{ij}\frac{C_W}{n_\ell}\EE\left( \sum_{\nu=1}^{n_\ell}z^\eell_{\nu;\aaA}z^\eell_{\nu;\aaB} \right) 
		= \delta_{ij}\frac{C_W}{n_\ell} \EE\big(z^\eell_{\aaA}\cdot  z^\eell_{\aaB}\big)\tag{3.11}\label{eq:correlatorGl}
	\end{align*}
\end{frame}
	 

\begin{frame}{Correlator camada $\ell +1$}
	\begin{itemize}
		\item Em suma, a equação \eqref{eq:correlatorGl} vira 
		 \begin{equation*}
			\EE\big(z^\eellum_{i;\aaA} z^\eellum_{j;\aaB}\big) = \delta_{ij}\frac{C_W}{n_\ell} \EE\big(z^\eell_{\aaA}\cdot  z^\eell_{\aaB}\big)\tag{3.11}
		 \end{equation*}
		 %\item Note que, novamente, no lado direito da equação acima, o único termo que depende das coordenadas $i,j$ é $\delta_{ij}$.
		 \item Em qualquer camada, o correlator das coordenadas $i,j$ é sempre o delta de Kronecker vezes um número que não depende das coordenadas, permitindo assim introduzir a notação 
		 \begin{equation*}\tag{3.12}\label{eq:Gldef}
			\EE\big(z^\eell_{i;\aaA}\ z^\eell_{j;\aaB}\big) = \delta_{ij} G^\eell_{\aaA\aaB}  
		 \end{equation*}
	\end{itemize}
\end{frame}

\begin{frame}{Recursão}
	\begin{itemize}
		\item Para isolar $G^\eell_{\aaA\aaB}$, vamos somar a equação \eqref{eq:Gldef} sobre todos os possíveis $i$ e $j$.
	\end{itemize}
	\begin{align*}
		\sum_{i,j=1}^{n_\ell} \EE\big(z^\eell_{i;\aaA} z^\eell_{j;\aaB}\big) &= \sum_{i,j=1}^{n_\ell} \delta_{ij} G^\eell_{\aaA\aaB} \\
		\sum_{\nu=1}^{n_\ell} \EE\big(z^\eell_{\nu;\aaA} z^\eell_{\nu;\aaB}\big) &= \sum_{\nu=1}^{n_\ell} \delta_{\nu\nu}G^\eell_{\aaA\aaB} \\
		\EE\left(\sum_{\nu=1}^{n_\ell}z^\eell_{\nu;\aaA} z^\eell_{\nu;\aaB}\right) &= \sum_{\nu=1}^{n_\ell} G^\eell_{\aaA\aaB} \\
		\EE\big(z^\eell_{\aaA}\cdot z^\eell_{\aaB}\big) &= n_\ell G^\eell_{\aaA\aaB} \\
	\end{align*}
\end{frame}

\begin{frame}{Recursão}
	\begin{equation*}\tag{3.13}\label{eq:Gl}
		G^\eell_{\aaA\aaB} = \frac{1}{n_\ell}\EE(z^\eell_{\aaA}\cdot z^\eell_{\aaB})		
	\end{equation*}
	Assim \eqref{eq:correlatorGl} se torna
	\begin{equation*}\tag{3.11'}\label{eq:correlatorGlfull}
		\EE\big(z^\eellum_{i;\aaA} z^\eellum_{j;\aaB}\big) = \delta_{ij}C_WG^\eell_{\aaA\aaB}
	\end{equation*}
	Usando \eqref{eq:correlatorGlfull}, podemos encontrar a recursão para $G^\eellum_{\aaA\aaB}$.
\end{frame}

\begin{frame}{Recursão}
	\begin{align*}\tag{3.14}\label{eq:tresquatorze}
		G^\eellum_{\aaA\aaB} &= \frac{1}{n_{\ell+1}}\EE\big(z^\eellum_{\aaA}\cdot z^\eellum_{\aaB}\big) \\
		&= \frac{1}{n_{\ell+1}}\EE\left(\sum_{\nu=1}^{n_{\ell+1}}z^\eellum_{\nu;\aaA} z^\eellum_{\nu;\aaB}\right) \\
		&= \frac{1}{n_{\ell+1}}\sum_{\nu=1}^{n_{\ell+1}} \EE\left(z^\eellum_{\nu;\aaA} z^\eellum_{\nu;\aaB}\right) \\
		&= \frac{1}{n_{\ell+1}}\sum_{\nu=1}^{n_{\ell+1}} \delta_{\nu\nu}C_WG^\eell_{\aaA\aaB} \\
		&= \frac{C_W}{n_{\ell+1}}\sum_{\nu=1}^{n_{\ell+1}} G^\eell_{\aaA\aaB} = \frac{C_W}{n_{\ell+1}}n_{\ell+1}G^\eell_{\aaA\aaB} = C_WG^\eell_{\aaA\aaB}\\ 
	\end{align*}
\end{frame}

\begin{frame}{Recursão}
	Da equação \eqref{eq:tresquatorze} obtemos a recursão
	\begin{equation*}\tag{3.15}\label{eq:trezquinze}
		G^\eell_{\aaA\aaB} = (C_W)^{\ell}G^{(0)}_{\aaA\aaB}
	\end{equation*}
\end{frame}

\begin{frame}{Física: Criticalidade}
	O observável $G^{(L)}_{\aaA\aaA}$ mede o tamanho médio do output da rede neural.
	\begin{equation*}\tag{3.16}
		G^{(L)}_{\aaA\aaA} = \frac{1}{n_L}\EE\left(z^{(L)}_\aaA\cdot z^{(L)}_\aaA\right) =  \frac{1}{n_L}\EE\left(\big\|z^{(L)}_\aaA\big\|^2\right)
	\end{equation*}

	Por outro lado, note que 
	$$G^{(L)}_{\aaA\aaA} = (C_W)^LG^{(0)}_{\aaA\aaA}$$
\end{frame}

\begin{frame}{Criticalidade}
	Assim, dependendo do valor da variância $C_W$, podemos ter três cenários:
	\begin{equation*}
		\lim_{L\to\infty} G^{(L)}_{\aaA\aaA} = \lim_{L\to\infty} (C_W)^LG^{(0)}_{\aaA\aaA} =
	\begin{cases}
		0  &\text{ se } C_W < 1  \\
		G^{(0)}_{\aaA\aaA}&\text{ se }  C_W = 1 \\
		\infty &\text{ se  } C_W>1\\
	\end{cases}
	\end{equation*}
\end{frame}

\begin{frame}{Criticalidade}
	\begin{itemize}
		\item Se $C_W < 1$, a rede neural não consegue aprender, pois o output tende a zero.
		\item Se $C_W > 1$, o valor do output diverge, o que significa instabilidade numérica.
		\item O único caso no qual a rede neural consegue aprender é quando $C_W = 1$.
	\end{itemize}
\end{frame}

% \begin{frame}{Questionamentos}
% 	\begin{itemize}
% 		\item Se a variância depender da camada, a recursão \eqref{eq:trezquinze} na última camada vira 
% 		\begin{equation*} 
% 			G^{(L)}_{\aaA\aaB} = G^{(0)}_{\aaA\aaB}\prod_{\nu=1}^{L}C_W^{(\nu)}
% 		\end{equation*}
% 		Nesse caso, podemos ter variâncias diferentes para cada camada, desde que mantenhamos seu produto igual a 1.
% 		\item Ficou faltando abrir o argumento para momentos de ordem ímpar.
% 	\end{itemize}
	
% \end{frame}
 
\subsection{Flutuacoes}

\begin{frame}
	\tableofcontents[currentsubsection]
\end{frame}

\begin{frame}{Salada de Índices}
	Novamente, para evitar subscrito duplo, vamos fazer as seguintes mudanças de notação:
	\begin{itemize}
		\item $i_1, i_2, i_3, i_4$ para $\mi1, \mi2, \mi3, \mi4$ 
		\item $j_1, j_2, j_3, j_4$ para $\mj1, \mj2, \mj3, \mj4$
	\end{itemize}
\end{frame}

\begin{frame}{Flutuações}
	\begin{itemize}
		\item O correlator de 4 pontos na camada $\ell$ é dado por
		$$\EE\big(z^\eell_{\mi1} z^\eell_{\mi2} z^\eell_{\mi3} z^\eell_{\mi4}\big)$$
		\item Vamos calcular o correlator de 4 pontos de maneira recursiva.
		\item Nessa sessão, vamos calcular as correlações em apenas uma entrada $x_\aaA$, e portanto vamos abandonar o índice.
	\end{itemize}
	
\end{frame}

\begin{frame}{Flutuações}
	\begin{itemize}
		\item Introduzimos a notação 
		\begin{equation*}\tag{3.17}
			G^\eell_2 := G^\eell_{\aaA\aaA}   = \frac{1}{n_\ell}\EE\left(z^\eell_{\aaA}\cdot z^\eell_{\aaA}\right) 
		\end{equation*}
		\item Em particular, na camada 0, 
		\begin{equation*}
			G^{(0)}_2 = \frac{1}{n_0}\EE\left(x_{\aaA}\cdot x_{\aaA}\right) = \frac{1}{n_0}x_{}\cdot x_{} 
		\end{equation*}
	\end{itemize}
\end{frame}

\begin{frame}{Teorema de Wick}
	\begin{block}{Teorema de Wick}
		Para calcular momentos superiores de uma variável aleatória $z$, usamos a fórmula 
		$$\EE\big(z_{\mi1} z_{\mi2} \ldots z_{\mi{2m}}\big) = \sum\EE(z_{\mi{k_1}}z_{\mi{k_2}})\EE(z_{\mi{k_3}}z_{\mi{k_4}})\ldots\EE(z_{\mi{k_{2m-1}}}z_{\mi{k_{2m}}})$$
		em que a soma é feita sobre todos os pareamentos possíveis dos índices.
	\end{block}
\end{frame}

\begin{frame}{Teorema de Wick -- ordem 4}
	\begin{itemize}
		\item O Teorema de Wick para 4 pontos nos diz que
	\end{itemize}
	\begin{multline*}
		\EE\big(z_{\mi1} z_{\mi2} z_{\mi3} z_{\mi4}\big) = \\
		\EE\big(z_{\mi1} z_{\mi2}\big)\EE\big(z_{\mi3} z_{\mi4}\big) 
		+ \EE\big(z_{\mi1} z_{\mi3}\big)\EE\big(z_{\mi2} z_{\mi4}\big)
		+ \EE\big(z_{\mi1} z_{\mi4}\big)\EE\big(z_{\mi2} z_{\mi3}\big)
	\end{multline*}
\end{frame}

\begin{frame}{Correlator 4 pontos -- camada 1}
	\begin{multline*}\tag{3.18}
		\EE\big(z^{(1)}_{\mi1} z^{(1)}_{\mi2} z^{(1)}_{\mi3} z^{(1)}_{\mi4}\big) = \EE\left(W^{(1)}_{\mi1*}\cdot x \ W^{(1)}_{\mi2*}\cdot x \ W^{(1)}_{\mi3*}\cdot x \ W^{(1)}_{\mi4*}\cdot x\right)\\
		= \EE\left( \sum_{\mj1=1}^{n_0}W^{(1)}_{\mi1\mj1} x_{\mj1} \sum_{\mj2=1}^{n_0}W^{(1)}_{\mi2\mj2} x_{\mj2} \sum_{\mj3=1}^{n_0}W^{(1)}_{\mi3\mj3} x_{\mj3} \sum_{\mj4=1}^{n_0}W^{(1)}_{\mi4\mj4} x_{\mj4}   \right)   \\ 
		= \sum_{\mj1,\mj2,\mj3,\mj4=1}^{n_0} \EE\left(W^{(1)}_{\mi1\mj1}W^{(1)}_{\mi2\mj2}W^{(1)}_{\mi3\mj3}W^{(1)}_{\mi4\mj4}\right) x_{\mj1}x_{\mj2}x_{\mj3}x_{\mj4} 
	\end{multline*}
	Aplicamos o Teorema de Wick para o termo com esperança, lembrando que $\EE\left(W^\eell_{ij}W^\eell_{kl}\right) = \delta_{ik}\delta_{jl}\frac{C_W}{n_{\ell-1}}$.
\end{frame}

\begin{frame}{Correlator 4 pontos -- camada 1}
	\small
	\begin{multline*}
		\EE\left(W^{(1)}_{\mi1\mj1}W^{(1)}_{\mi2\mj2}W^{(1)}_{\mi3\mj3}W^{(1)}_{\mi4\mj4}\right) = 
		\EE\left(W^{(1)}_{\mi1\mj1}W^{(1)}_{\mi2\mj2}\right)\EE\left(W^{(1)}_{\mi3\mj3}W^{(1)}_{\mi4\mj4}\right) + \\[1mm]
		\EE\left(W^{(1)}_{\mi1\mj1}W^{(1)}_{\mi3\mj3}\right)\EE\left(W^{(1)}_{\mi2\mj2}W^{(1)}_{\mi4\mj4}\right) + 	
		\EE\left(W^{(1)}_{\mi1\mj1}W^{(1)}_{\mi4\mj4}\right)\EE\left(W^{(1)}_{\mi2\mj2}W^{(1)}_{\mi2\mj3}\right) = \\[1mm]
		\delta_{\mi1\mi2}\delta_{\mj1\mj2}\frac{C_W}{n_0}\delta_{\mi3\mi4}\delta_{\mj3\mj4}\frac{C_W}{n_0} + 
		\delta_{\mi1\mi3}\delta_{\mj1\mj3}\frac{C_W}{n_0}\delta_{\mi2\mi4}\delta_{\mj2\mj4}\frac{C_W}{n_0} + \\
		 \delta_{\mi1\mi4}\delta_{\mj1\mj4}\frac{C_W}{n_0}\delta_{\mi2\mi3}\delta_{\mj2\mj3}\frac{C_W}{n_0} =
	\end{multline*}
\end{frame}
\begin{frame}{Correlator 4 pontos -- camada 1}
	Agrupando os termos, obtemos
	\begin{multline*}
		\EE\left(W^{(1)}_{\mi1\mj1}W^{(1)}_{\mi2\mj2}W^{(1)}_{\mi3\mj3}W^{(1)}_{\mi4\mj4}\right) =\\= \frac{C_W^2}{n_0^2}\left(\delta_{\mi1\mi2}\delta_{\mj1\mj2}\delta_{\mi3\mi4}\delta_{\mj3\mj4} + \delta_{\mi1\mi3}\delta_{\mj1\mj3} \delta_{\mi2\mi4}\delta_{\mj2\mj4} + \delta_{\mi1\mi4}\delta_{\mj1\mj4} \delta_{\mi2\mi3}\delta_{\mj2\mj3}\right)
	\end{multline*}
	Voltando para (3.18), obtemos
\end{frame}
\begin{frame}{Correlator 4 pontos -- camada 1}\small
	\begin{multline*}
		\EE\big(z^{(1)}_{\mi1} z^{(1)}_{\mi2} z^{(1)}_{\mi3} z^{(1)}_{\mi4}\big) = \\
		\frac{C_W^2}{n_0^2}\sum_{\mj1,\mj2,\mj3,\mj4=1}^{n_0} 
		%\left(\delta_{\mi1\mi2}\delta_{\mj1\mj2}\delta_{\mi3\mi4}\delta_{\mj3\mj4} + \delta_{\mi1\mi3}\delta_{\mj1\mj3} \delta_{\mi2\mi4}\delta_{\mj2\mj4} + \delta_{\mi1\mi4}\delta_{\mj1\mj4} \delta_{\mi2\mi3}\delta_{\mj2\mj3}\right) 
		\left(\begin{array}{r}
			\delta_{\mi1\mi2}\delta_{\mj1\mj2}\delta_{\mi3\mi4}\delta_{\mj3\mj4} \hspace{6ex} \\[1mm] 
			+\delta_{\mi1\mi3}\delta_{\mj1\mj3} \delta_{\mi2\mi4}\delta_{\mj2\mj4} \hspace{3ex} \\[1mm]
			+  \delta_{\mi1\mi4}\delta_{\mj1\mj4} \delta_{\mi2\mi3}\delta_{\mj2\mj3}
		\end{array}\right)
		x_{\mj1}x_{\mj2}x_{\mj3}x_{\mj4}
	\end{multline*}
	Vamos nos atentar ao primeiro grupo de deltas, e os outros saem de maneira análoga.
\end{frame}

\begin{frame}{Correlator 4 pontos -- camada 1}
	Os índices `chapéu' são fixos, então podemos retirar da soma
	\begin{multline*}
		\sum_{\mj1,\mj2,\mj3,\mj4=1}^{n_0}\hspace{-2mm}\delta_{\mi1\mi2}\delta_{\mj1\mj2}\delta_{\mi3\mi4}\delta_{\mj3\mj4} x_{\mj1}x_{\mj2}x_{\mj3}x_{\mj4}  = 
		\delta_{\mi1\mi2}\delta_{\mi3\mi4}\hspace{-2mm}\sum_{\mj1,\mj2,\mj3,\mj4=1}^{n_0}\hspace{-2mm}\delta_{\mj1\mj2}\delta_{\mj3\mj4} x_{\mj1}x_{\mj2}x_{\mj3}x_{\mj4} 
	\end{multline*}
	O primeiro delta só é diferente de zero quando $\mj1 = \mj2$, assim fazemos a mudança de variáveis $\nu = \mj1 = \mj2$. 
	De modo análogo, $\mu = \mj3 = \mj4$. Assim, obtemos
	\small
	\begin{multline*}
		\delta_{\mi1\mi2}\delta_{\mi3\mi4}\sum_{\nu,\mu=1}^{n_0}\delta_{\nu\nu}\delta_{\mu\mu} x_{\nu}x_{\nu}x_{\mu}x_{\mu} =
	\delta_{\mi1\mi2}\delta_{\mi3\mi4}\sum_{\nu=1}^{n_0}x_{\nu}x_{\nu} \sum_{\mu=1}^{n_0}x_{\mu}x_{\mu} \\
	= \delta_{\mi1\mi2}\delta_{\mi3\mi4} (x\cdot x)^2
	\end{multline*}
\end{frame}

\begin{frame}{Correlator 4 pontos -- camada 1}
	Voltando para (3.18), obtemos
	\begin{multline*}\tag{3.18}\label{eq:tresdezoito}
		\EE\big(z^{(1)}_{\mi1} z^{(1)}_{\mi2} z^{(1)}_{\mi3} z^{(1)}_{\mi4}\big) = \\
		 = \frac{C_W^2}{n_0^2}\left(\delta_{\mi1\mi2}\delta_{\mi3\mi4} (x\cdot x)^2 + \delta_{\mi1\mi3}\delta_{\mi2\mi4} (x\cdot x)^2 + \delta_{\mi1\mi4}\delta_{\mi2\mi3} (x\cdot x)^2 \right) \\
		 = \frac{C_W^2}{n_0^2} (x\cdot x)^2 \left(\delta_{\mi1\mi2}\delta_{\mi3\mi4} + \delta_{\mi1\mi3}\delta_{\mi2\mi4} + \delta_{\mi1\mi4}\delta_{\mi2\mi3} \right)\\
		 = C_W^2 \left(\frac{x\cdot x}{n_0}\right)^2 \left(\delta_{\mi1\mi2}\delta_{\mi3\mi4} + \delta_{\mi1\mi3}\delta_{\mi2\mi4} + \delta_{\mi1\mi4}\delta_{\mi2\mi3} \right)\\
		 = C_W^2 \left(G^{(0)}_2 \right)^2\left(\delta_{\mi1\mi2}\delta_{\mi3\mi4} + \delta_{\mi1\mi3}\delta_{\mi2\mi4} + \delta_{\mi1\mi4}\delta_{\mi2\mi3} \right)
	\end{multline*}
\end{frame}

\begin{frame}{Correlator 4 pontos -- camada $\ell$}
	\begin{itemize}
		\item O mesmo raciocínio pode ser aplicado para a camada $\ell$, e obtemos
	\end{itemize}\small
	\begin{multline*}\tag{3.20}
		\EE\big(z^\eellum_{\mi1} z^\eellum_{\mi2} z^\eellum_{\mi3} z^\eellum_{\mi4}\big) = \\
		\EE\left(W^\eellum_{\mi1*}z^\eell \ W^\eellum_{\mi2*}z^\eell \ W^\eellum_{\mi3*}z^\eell \ W^\eellum_{\mi4*}z^\eell \right) = \\
		\EE\left(\sum_{\mj1=1}^{n_\ell}\! W^\eellum_{\mi1\mj1}z^\eell_{\mj1} \sum_{\mj2=1}^{n_\ell}\! W^\eellum_{\mi2\mj2}z^\eell_{\mj2} 
		\sum_{\mj3=1}^{n_\ell}\! W^\eellum_{\mi3\mj3}z^\eell_{\mj3}  \sum_{\mj4=1}^{n_\ell} \! W^\eellum_{\mi4\mj4}z^\eell_{\mj4} \right) = \\
		\sum_{\mj1,\mj2,\mj3,\mj4=1}^{n_\ell}\! \EE\left(W^\eellum_{\mi1\mj1}W^\eellum_{\mi2\mj2}W^\eellum_{\mi3\mj3}W^\eellum_{\mi4\mj4} z^\eell_{\mj1}z^\eell_{\mj2}z^\eell_{\mj3}z^\eell_{\mj4}\right)
	\end{multline*}
\end{frame}

\begin{frame}{Correlator 4 pontos -- camada $\ell$}
	O que acontece na camada $\ell+1$ é independente do que acontece na camada $\ell$, então a esperança do produto é o produto das esperanças.
	\begin{multline*}\tag{3.20}
		\sum_{\mj1,\mj2,\mj3,\mj4=1}^{n_\ell}\hspace{-2ex}\EE\left(W^\eellum_{\mi1\mj1}W^\eellum_{\mi2\mj2}W^\eellum_{\mi3\mj3}W^\eellum_{\mi4\mj4} z^\eell_{\mj1}z^\eell_{\mj2}z^\eell_{\mj3}z^\eell_{\mj4}\right)
 = \\ \sum_{\mj1,\mj2,\mj3,\mj4=1}^{n_\ell}\hspace{-2ex}\EE\left(W^\eellum_{\mi1\mj1}W^\eellum_{\mi2\mj2}W^\eellum_{\mi3\mj3}W^\eellum_{\mi4\mj4} \right)\EE\left( z^\eell_{\mj1}z^\eell_{\mj2}z^\eell_{\mj3}z^\eell_{\mj4}\right)
	\end{multline*}
\end{frame}

\begin{frame}{Correlator 4 pontos -- camada $\ell$}
	Usando o Teorema de Wick, e fazendo o mesmo cálculo que fizemos para a camada 1, obtemos
	\begin{multline*}
		\EE\left(W^\eellum_{\mi1\mj1}W^\eellum_{\mi2\mj2}W^\eellum_{\mi3\mj3}W^\eellum_{\mi4\mj4} \right) = \\
		\EE\left(W^\eellum_{\mi1\mj1}W^\eellum_{\mi2\mj2}\right)\EE\left(W^\eellum_{\mi3\mj3}W^\eellum_{\mi4\mj4}\right) + \\
		\EE\left(W^\eellum_{\mi1\mj1}W^\eellum_{\mi3\mj3}\right)\EE\left(W^\eellum_{\mi2\mj2}W^\eellum_{\mi4\mj4}\right) + \\
		\EE\left(W^\eellum_{\mi1\mj1}W^\eellum_{\mi4\mj4}\right)\EE\left(W^\eellum_{\mi2\mj2}W^\eellum_{\mi3\mj3}\right) = \\
		\frac{C_W^2}{n_\ell^2}\left(\delta_{\mi1\mi2}\delta_{\mj1\mj2}\delta_{\mi3\mi4}\delta_{\mj3\mj4} + \delta_{\mi1\mi3}\delta_{\mj1\mj3} \delta_{\mi2\mi4}\delta_{\mj2\mj4} + \delta_{\mi1\mi4}\delta_{\mj1\mj4} \delta_{\mi2\mi3}\delta_{\mj2\mj3}\right)
	\end{multline*}
	Voltando para (3.20), obtemos
\end{frame}

\begin{frame}{Correlator 4 pontos -- camada $\ell$}
	\begin{multline*}\tag{3.20}\EE\big(z^\eellum_{\mi1} z^\eellum_{\mi2} z^\eellum_{\mi3} z^\eellum_{\mi4}\big) = \\
		= \sum_{\mj1,\mj2,\mj3,\mj4=1}^{n_\ell}\frac{C_W^2}{n_\ell^2}\left(\begin{array}{r}
			\delta_{\mi1\mi2}\delta_{\mj1\mj2}\delta_{\mi3\mi4}\delta_{\mj3\mj4} \hspace{6ex} \\[1mm] 
			+\delta_{\mi1\mi3}\delta_{\mj1\mj3} \delta_{\mi2\mi4}\delta_{\mj2\mj4} \hspace{3ex} \\[1mm]
			+  \delta_{\mi1\mi4}\delta_{\mj1\mj4} \delta_{\mi2\mi3}\delta_{\mj2\mj3}
		\end{array}\right)\EE\left( z^\eell_{\mj1}z^\eell_{\mj2}z^\eell_{\mj3}z^\eell_{\mj4}\right)
	\end{multline*}
	Vamos nos concentrar no  primeiro grupo de deltas
\end{frame}

\begin{frame}{Correlator 4 pontos -- camada $\ell$}
	\begin{multline*}
		\sum_{\mj1,\mj2,\mj3,\mj4=1}^{n_\ell} \delta_{\mi1\mi2}\delta_{\mj1\mj2}\delta_{\mi3\mi4}\delta_{\mj3\mj4} \EE\left( z^\eell_{\mj1}z^\eell_{\mj2}z^\eell_{\mj3}z^\eell_{\mj4}\right) = \\
		= \delta_{\mi1\mi2}\delta_{\mi3\mi4}\sum_{\mj1,\mj2,\mj3,\mj4=1}^{n_\ell} \delta_{\mj1\mj2}\delta_{\mj3\mj4} \EE\left( z^\eell_{\mj1}z^\eell_{\mj2}z^\eell_{\mj3}z^\eell_{\mj4}\right) 
	\end{multline*}
Novamente, fazendo $\nu = \mj1 = \mj2$, $\mu = \mj3 = \mj4$, temos
\begin{multline*}
		\delta_{\mi1\mi2}\delta_{\mi3\mi4}\sum_{\nu,\mu=1}^{n_\ell} \delta_{\nu\nu}\delta_{\mu\mu} \EE\left( z^\eell_{\nu}z^\eell_{\nu}z^\eell_{\mu}z^\eell_{\mu}\right) = \\ 
		=\delta_{\mi1\mi2}\delta_{\mi3\mi4}\sum_{\nu,\mu=1}^{n_\ell} \EE\left( z^\eell_{\nu}z^\eell_{\nu} z^\eell_{\mu}z^\eell_{\mu}\right)
\end{multline*}
\end{frame}

\begin{frame}{Correlator 4 pontos -- camada $\ell$}
	Aplicando a ideia acima para todos os os grupos de deltas, obtemos
	\begin{multline*}\tag{3.20}
		\EE\big(z^\eellum_{\mi1} z^\eellum_{\mi2} z^\eellum_{\mi3} z^\eellum_{\mi4}\big) = \\
		\sum_{\mj1,\mj2,\mj3,\mj4=1}^{n_\ell}\frac{C_W^2}{n_\ell^2}\left(\begin{array}{r}
			\delta_{\mi1\mi2}\delta_{\mj1\mj2}\delta_{\mi3\mi4}\delta_{\mj3\mj4} \hspace{6ex} \\[1mm] 
			+\delta_{\mi1\mi3}\delta_{\mj1\mj3} \delta_{\mi2\mi4}\delta_{\mj2\mj4} \hspace{3ex} \\[1mm]
			+  \delta_{\mi1\mi4}\delta_{\mj1\mj4} \delta_{\mi2\mi3}\delta_{\mj2\mj3}
		\end{array}\right)\EE\left( z^\eell_{\mj1}z^\eell_{\mj2}z^\eell_{\mj3}z^\eell_{\mj4}\right) = \\
		= \frac{C_W^2}{n_\ell^2}\left(\delta_{\mi1\mi2}\delta_{\mi3\mi4}+\delta_{\mi1\mi3}\delta_{\mi2\mi4}+ \delta_{\mi1\mi4}\delta_{\mi2\mi3}\right)\sum_{\nu,\mu=1}^{n_\ell} \EE\left( z^\eell_{\nu}z^\eell_{\nu} z^\eell_{\mu}z^\eell_{\mu}\right)
	\end{multline*}
\end{frame}

\begin{frame}{Correlator 4 pontos -- camada $\ell$}
	\begin{itemize}
		\item Novamente, podemos argumentar que o correlator de 4 pontos é proporcional ao fator 
		 $$\wickquatro $$
		que chamaremos de \textit{fator Wick 4}.
		\item Chamando a constante de proporcionalidade de $G_4^\eell$, escrevemos a relação
	\end{itemize}

	\begin{equation*}\tag{3.21}
		\EE\left(z^\eell _\mi1 z^\eell_\mi2 z^\eell_\mi3 z^\eell_\mi4\right) = \left(\wickquatro \right)G_4^\eell
	\end{equation*}
\end{frame}

\begin{frame}{Correlator 4 pontos -- camada $\ell$}
	Comparando (3.21) com (3.18), obtemos a relação
	\begin{equation*}\tag{3.22}
		G_4^{(1)} = {C_W^2}\left(G_2^{(0)}\right)^2
	\end{equation*}
\end{frame}

\begin{frame}{Correlator 4 pontos -- camada $\ell$}
	Aplicando (3.21) no somatório que aparece (3.20), obtemos
	{\small
	\begin{multline*}\tag{3.23}
		\sum_{\nu,\mu=1}^{n_\ell} \EE\left( z^\eell_{\nu}z^\eell_{\nu} z^\eell_{\mu}z^\eell_{\mu}\right)
		= \sum_{\nu,\mu=1}^{n_\ell} \left( \delta_{\nu\nu}\delta_{\mu\mu} + \delta_{\nu\mu}\delta_{\nu\mu} + \delta_{\nu\mu}\delta_{\nu\mu}\right)G^\eell_4=\\
		= \sum_{\nu,\mu=1}^{n_\ell}  \left( \delta_{\nu\nu}\delta_{\mu\mu} + 2\delta_{\nu\mu}\delta_{\nu\mu}\right)G^\eell_4
		\end{multline*}
	}\begin{itemize}
			\item O primeiro par de deltas é sempre 1, então essa primeira parte da soma é $n_\ell^2$.
			\item O segundo par de deltas só é diferente de zero quando $\nu = \mu$, então essa segunda parte da soma é $n_\ell$.
			\item Portanto, a soma total é $\left(n_\ell^2 + 2n_\ell\right)G^\eell_4$.
		\end{itemize}
\end{frame}

\begin{frame}{Correlator 4 pontos -- camada $\ell$}
	Voltando para (3.20),\small
	\begin{multline*}
		\EE\big(z^\eellum_{\mi1} z^\eellum_{\mi2} z^\eellum_{\mi3} z^\eellum_{\mi4}\big) = \\
		= \frac{C_W^2}{n_\ell^2}\left(\wickquatro \right)\sum_{\nu,\mu=1}^{n_\ell} \EE\left( z^\eell_{\nu}z^\eell_{\nu} z^\eell_{\mu}z^\eell_{\mu}\right)= \\
		= \frac{C_W^2}{n_\ell^2}\left(\wickquatro \right)\left(n_\ell^2 + 2n_\ell\right)G^\eell_4 = \\
		= \left(\wickquatro \right) \left(1 + \frac{2}{n_\ell}\right)C_W^2 G^\eell_4
	\end{multline*}
\end{frame}

\begin{frame}{Correlator 4 pontos -- Recorrência}
	Por outro lado, definimos que o correlator de 4 pontos na camada $\ell+1$ é dado pelo fator Wick 4 multiplicado pela constante de proporcionalidade $G_4^\eellum$. Assim, podemos escrever a recorrência
	\begin{equation*}\tag{3.24}
		G_4^{(\ell+1)} = {C_W^2}\left(1 + \frac{2}{n_\ell}\right)G_4^{(\ell)}
	\end{equation*}
\end{frame}

\begin{frame}{Correlator 4 pontos -- Recorrência}
	Se abrirmos essa recursão da camada $\ell$ até a camada 1, e aplicamos (3.22), obtemos

	\begin{multline*}
		G_4^\eell\! =\! \left[\prod_{\mi{\ell}=1}^{\ell-1}C_W^2\left(1 + \frac{2}{n_{\mi{\ell}}}\right)\right]\!G_4^{(1)} 
		= \left(C_W^2\right)^{\ell-1}G_4^{(1)}\prod_{\mi{\ell}=1}^{\ell-1}\left(1 + \frac{2}{n_{\mi{\ell}}}\right) \\ = \left(C_W^2\right)^{\ell-1}C_W^2\left(G_2^{(0)}\right)^2\prod_{\mi{\ell}=1}^{\ell-1}\left(1 + \frac{2}{n_{\mi{\ell}}}\right)  = \\=  \left(C_W^{\ell}G_2^{(0)}\right)^2\prod_{\mi{\ell}=1}^{\ell-1}\left(1 + \frac{2}{n_{\mi{\ell}}}\right)
	\end{multline*} 
\end{frame}

\begin{frame}{Correlator 4 pontos -- Recorrência}
	Aplicando \eqref{eq:trezquinze}, o fator $C_W^{\ell}G_2^{(0)} = G_2^\eell$, e obtemos
	\begin{equation*}\tag{3.25}
		G_4^\eell = \left(G_2^\eell\right)^2\prod_{\mi{\ell}=1}^{\ell-1}\left(1 + \frac{2}{n_{\mi{\ell}}}\right)
	\end{equation*}
	que relaciona o correlator de 4 pontos com o correlator de 2 pontos.

\end{frame}

\begin{frame}{Física: Flutuações}
	\begin{itemize}
		\item Equalizando o número de neurônios em todas as camadas $n_i = n, i=1,\ldots,L$, a equação (3.25) se torna
	\begin{equation*}\tag{3.25'}
		G_4^\eell = \left(G_2^\eell\right)^2\left(1 + \frac{2}{n}\right)^{\ell-1}
	\end{equation*}
	\item Se fizermos $n\to\infty$, o correlator de 4 pontos converge para
	\begin{equation*}
		G_4^\eell = \left(G_2^\eell\right)^2
	\end{equation*}
	o que tornaria a distribuição gaussiana.
\end{itemize}
\end{frame}

\begin{frame}{Física: Flutuações}
	Para medir o desvio da gaussianidade, usamos a aproximação de Taylor centrada em 0 para $$(1+x)^{\ell-1} \approx 1 + (\ell-1)x + O(x^2)$$ e obtemos

\begin{align*}\tag{3.28}
	G_4^\eell  - \left(G_2^\eell\right)^2 &=  \left(G_2^\eell\right)^2\left[\left(1 + \frac{2}{n}\right)^{\ell-1}-1\right] \\
	&= \left(G_2^\eell\right)^2\left[\frac{2}{n}(\ell-1) + O\left(\frac{1}{n^2}\right)\right] \\
	&= \frac{2(\ell-1)}{n}\left(G_2^\eell\right)^2 + O\left(\frac{1}{n^2}\right)
\end{align*}
\end{frame}

\begin{frame}{Escala emergente}
	\begin{itemize}
		\item O desvio da gaussianidade é proporcional ao número de camadas $\ell$ e inversamente proporcional ao número de neurônios $n$.
		\item A magnitude do desvio é proporcional ao quociente $\frac{\ell}{n}$, chamado de \textit{escala emergente}.
	\end{itemize}
\end{frame}

\begin{frame}{Correlator conexo}
	O correlator de 4 pontos conexo tem a fórmula:
\begin{align*}\tag{1.54}
	\left.\EE(z_{\mi1} z_{\mi2} z_{\mi3} z_{\mi4})\right|_C &= \EE(z_{\mi1} z_{\mi2} z_{\mi3} z_{\mi4}) - \EE(z_{\mi1} z_{\mi2})\EE(z_{\mi3} z_{\mi4}) \\
	& - \EE(z_{\mi1} z_{\mi3})\EE(z_{\mi2} z_{\mi4}) - \EE(z_{\mi1} z_{\mi4})\EE(z_{\mi2} z_{\mi3}) 
\end{align*}
\begin{itemize}
	\item O teorema de Wick garante que se a distribuição for gaussiana, o correlator de 4 pontos conexo é zero.
	\item Valores diferentes de zero indicam o desvio da gaussianidade.
\end{itemize}
\end{frame}

\begin{frame}{Correlator conexo}
	Utilizando as equações (3.21) e (3.12), obtemos a fórmula para o correlator de 4 pontos conexo
	\small
	\begin{align*}\tag{3.29}
	\left.\EE(z_{\mi1} z_{\mi2} z_{\mi3} z_{\mi4})\right|_C &=  \left(\wickquatro \right)G_4^\eell  \\
	 &- \delta_{\mi1\mi2}G_2^\eell  \delta_{\mi3\mi4}G_2^\eell  - \delta_{\mi1\mi3}G_2^\eell\delta_{\mi2\mi4}  G_2^\eell  \\
	 &- \delta_{\mi1\mi4}G_2^\eell\delta_{\mi2\mi3}  G_2^\eell  \\
	 &=  \left(\wickquatro \right)\left(G_4^\eell - \left(G_2^\eell\right)^2\right)
	\end{align*}
\end{frame}

\begin{frame}{Interações}
	Outra maneira de interpretar a não-gaussianidade é através das interações: quebras da independência estatística entre os neurônios.
	Para $\mi1=\mi2=j \neq \mi3=\mi4=k$ {\small
	\begin{multline*}\tag{3.30}
		\EE\left( \left(z_j^\eell z_j^\eell - G_2^\eell\right)  \left(z_k^\eell z_k^\eell - G_2^\eell\right) \right) = \\
		= \EE\left(z_j^\eell z_j^\eell z_k^\eell z_k^\eell\right) - G^\eell_2\EE\left(z_j^\eell z_j^\eell\right) - G^\eell_2\EE\left(z_k^\eell z_k^\eell\right)  + G_2^{\eell^2} = \\
		= (1+0+0)G_4^\eell - G_2^\eell \delta_{jj}G_2^\eell - G_2^\eell \delta_{kk}G_2^\eell + G_2^{\eell^2} \\
		= G_4^\eell - G_2^{\eell^2} 
	\end{multline*}
	}
	\begin{itemize}
		\item O quanto $z_jz_j$ desvia de sua média $G_2^\eell$ está correlacionado com o quanto $z_kz_k$ desvia de sua média $G_2^\eell$.
	\end{itemize}
\end{frame}

\begin{frame}{Observável}
	Observável
	\begin{equation*}
		\OO^\eell := \frac{1}{n}z^\eell\cdot z^\eell
	\end{equation*}
mede a magnitude média do vetor de ativação na camada $\ell$. Seu valor médio é
	\begin{equation*}
		\EE\left(\OO^\eell\right) = \frac{1}{n}\EE\left(z^\eell\cdot z^\eell\right) = G_2^\eell
	\end{equation*}

Quanto esse observável desvia de sua média?
\end{frame}

\begin{frame}{Observável}
	\small
	\begin{multline*}
		\EE\left(\left(\OO^\eell - G_2^\eell\right)^2\right) = \EE\left(\OO^{\eell^2}\right) - 2G_2^\eell \EE\left(\OO^\eell\right) + \left(G_2^\eell\right)^2 \\
		= \EE\left(\left(\frac{1}{n} z^\eell \cdot z\eell\right)^2\right) - \left(G_2^\eell\right)^2 \\
		= \frac{1}{n^2}\EE\left(\sum_{\mu=1}^{n} z_\mu^\eell z_\mu^\eell \sum_{\nu=1}^{n}z_\nu^\eell z_\nu^\eell \right) - \left(G_2^\eell\right)^2 \\
		= \frac{1}{n^2}\sum_{\mu,\nu=1}^{n} \EE\left(z_\mu^\eell z_\mu^\eell z_\nu^\eell z_\nu^\eell \right) - \left(G_2^\eell\right)^2 \\
		= \frac{1}{n^2}\sum_{\mu,\nu=1}^{n}\left( \delta_{\nu\nu}\delta_{\mu\mu} + 2\delta_{\nu\mu}\delta_{\nu\mu} \right)G_4^\eell - \left(G_2^\eell\right)^2 \\
		= \frac{1}{n^2}\left(n^2 + 2n\right)G_4^\eell - \left(G_2^\eell\right)^2 
		= \left(1+\frac{2}{n}\right)G_4^\eell -  \left(G_2^\eell\right)^2  
	\end{multline*}
\end{frame}

\begin{frame}{Observável}
	Aqui, vamos utilizar (3.25'), que nos diz que $$G_4^\eell = \left(G_2^\eell\right)^2\left(1 + \frac{2}{n}\right)^{\ell-1}$$
	Logo, multiplicando tudo pelo fator $(1+2/n)$, obtemos
	$$\left(1+\frac{2}{n}\right)G_4^\eell = \left(G_2^\eell\right)^2\left(1 + \frac{2}{n}\right)^{\ell}$$ 
	e assim
	\begin{align*}
		\left(1+\frac{2}{n}\right)G_4^\eell - \left(G_2^\eell\right)^2 &= \left(G_2^\eell\right)^2\left[\left(1 + \frac{2}{n}\right)^{\ell} - 1\right] \\
		&= \left(G_2^\eell\right)^2\left[\frac{2}{n}\ell + O\left(\frac{1}{n^2}\right)\right] \\
		\end{align*}
\end{frame}

\begin{frame}{Observável}
	Com isso, concluímos que 
	\begin{align*}\tag{3.33}
		\EE\left(\left(\OO^\eell - G_2^\eell\right)^2\right) &=
		\left(1+\frac{2}{n}\right)G_4^\eell -  \left(G_2^\eell\right)^2 \\
		&= \frac{2\ell}{n}\left(G_2^\eell\right)^2 + O\left(\frac{1}{n^2}\right) \\
	\end{align*}

	Assim, a escala emergente $\frac{\ell}{n}$  mede a magnitude do desvio do observável $\OO^\eell$ de sua média $G_2^\eell$.
\end{frame}

\subsection{Caos}

\begin{frame}
	\tableofcontents[currentsubsection]
\end{frame}

\begin{frame}{Correlator de 6 pontos}
\begin{itemize}
	\item Pra calcular o correlator de 6 pontos, precisamos do \textit{fator Wick 6}. 
	\item Como vou construir esse monstro de 15 termos?
	\item Usando a ordem dentro de cada par.
	\item Fixo o par (1,2) e faço os 3 agrupamentos dos indices 3, 4, 5 6.
	\item Passo pro par (1,3) e faço os 3 agrupamentos dos índices 2, 4, 5, 6.
	\item E assim por diante.
\end{itemize}	
\end{frame}

\begin{frame}{Fator Wick 6}
	
	\begin{equation*}
		\Wick_6 = 
		\begin{array}{c c c}
			+ \ddelta12 \ddelta34 \ddelta56 & +\ddelta12 \ddelta35 \ddelta46 & +\ddelta12 \ddelta36 \ddelta45 \\[1mm]
			+ \ddelta13 \ddelta24 \ddelta56 & +\ddelta13 \ddelta25 \ddelta46 & +\ddelta13 \ddelta26 \ddelta45 \\[1mm]
			+ \ddelta14 \ddelta23 \ddelta56 & +\ddelta14 \ddelta25 \ddelta36 & +\ddelta14 \ddelta26 \ddelta35 \\[1mm]
			+ \ddelta15 \ddelta23 \ddelta46 & +\ddelta15 \ddelta24 \ddelta36 & +\ddelta15 \ddelta26 \ddelta34 \\[1mm]
			+ \ddelta16 \ddelta23 \ddelta45 & +\ddelta16 \ddelta24 \ddelta35 & +\ddelta16 \ddelta25 \ddelta34
		\end{array}
	\end{equation*}
\end{frame}

\begin{frame}{Correlator de 6 pontos}
	Assim, o correlator de 6 pontos é dado por
	\small
	\begin{multline*}\tag{3.36}
		\EE\left(z_{\mi1}^\eellum z_{\mi2}^\eellum z_{\mi3}^\eellum z_{\mi4}^\eellum z_{\mi5}^\eellum z_{\mi6}^\eellum\right) =  \\
				= \sum_{\substack{\mj{k}=1\\k=1\ldots 6}}^{n_\ell} \EE\left( W_{\mi1 \mj1}^\eellum W_{\mi2 \mj2}^\eellum W_{\mi3 \mj3}^\eellum W_{\mi4 \mj4}^\eellum W_{\mi5 \mj5}^\eellum W_{\mi6 \mj6}^\eellum \right)\\\EE\big(z_{\mj1}^\eell z_{\mj2}^\eell z_{\mj3}^\eell z_{\mj4}^\eell z_{\mj5}^\eell z_{\mj6}^\eell\big) = \\
				= \frac{C_W^3}{n_\ell^3}(\Wick_6)\sum_{\mu,\nu,\kappa=1}^{n_\ell} \EE\left(z_{\mu}^\eell z_{\mu}^\eell z_{\nu}^\eell z_{\nu}^\eell z_{\kappa}^\eell z_{\kappa}^\eell\right) 
	\end{multline*} 
\end{frame}

\begin{frame}{Recorrência}
	Novamente, assumimos que o correlator de 6 pontos tem a forma
	\begin{equation*}\tag{3.37}
		\EE\left(z_{\mi1}^\eell z_{\mi2}^\eell z_{\mi3}^\eell z_{\mi4}^\eell z_{\mi5}^\eell z_{\mi6}^\eell\right) = \left(\Wick_6 \right)G_6^\eell
	\end{equation*}

	Para calcular $G_6^\eell$, vamos usar a mesma ideia que usamos para o correlator de 4 pontos, e precisamos calcular 
	$$\sum_{\mu,\nu,\kappa=1}^{n_\ell} \EE\left(z_{\mu}^\eell z_{\mu}^\eell z_{\nu}^\eell z_{\nu}^\eell z_{\kappa}^\eell z_{\kappa}^\eell\right) $$
\end{frame}

\begin{frame}{Fator Wick 6 -- 3 grupos} 
	Fazendo $\mu=\mi1=\mi2$, $\nu=\mi3=\mi4$, $\kappa=\mi5=\mi6$, na fórmula para $\Wick_6$, obtemos
 
	\begin{equation*}
		\Wick_6^3 = 
		\begin{array}{c c c}
			\color{green}+ \ddelta{\mu}{\mu} \ddelta{\nu}{\nu} \ddelta{\kappa}{\kappa} &\color{blue} +\ddelta{\mu}{\mu} \ddelta{\nu}{\kappa} \ddelta{\nu}{\kappa} & \color{blue}+\ddelta{\mu}{\mu} \ddelta{\nu}{\kappa} \ddelta{\nu}{\kappa} \\[1mm]
			\color{blue}+ \ddelta{\mu}{\nu} \ddelta{\mu}{\nu} \ddelta{\kappa}{\kappa} & +\ddelta{\mu}{\nu} \ddelta{\mu}{\kappa} \ddelta{\nu}{\kappa} & +\ddelta{\mu}{\nu} \ddelta{\mu}{\kappa} \ddelta{\nu}{\kappa} \\[1mm]
			\color{blue}+ \ddelta{\mu}{\nu} \ddelta{\mu}{\nu} \ddelta{\kappa}{\kappa} & +\ddelta{\mu}{\nu} \ddelta{\mu}{\kappa} \ddelta{\nu}{\kappa} & +\ddelta{\mu}{\nu} \ddelta{\mu}{\kappa} \ddelta{\nu}{\kappa} \\[1mm]
			+ \ddelta{\mu}{\kappa} \ddelta{\mu}{\nu} \ddelta{\nu}{\kappa} & +\ddelta{\mu}{\kappa} \ddelta{\mu}{\nu} \ddelta{\nu}{\kappa} & \color{blue} +\ddelta{\mu}{\kappa} \ddelta{\mu}{\kappa} \ddelta{\nu}{\nu} \\[1mm]
			+ \ddelta{\mu}{\kappa} \ddelta{\mu}{\nu} \ddelta{\nu}{\kappa} & +\ddelta{\mu}{\kappa} \ddelta{\mu}{\nu} \ddelta{\nu}{\kappa} & \color{blue} +\ddelta{\mu}{\kappa} \ddelta{\mu}{\kappa} \ddelta{\nu}{\nu}
		\end{array}
	\end{equation*}
\end{frame}

\begin{frame}{Contando agrupamentos}
	Temos 
	\begin{itemize}
		\item 1 termo $\delta_{ii}\delta_{jj}\delta_{kk}$ em {\color{green} verde}, cujo valor é sempre 1 em todas as $n_\ell^3$ ocorrências;
		\item 6 termos do tipo  $\delta_{ii}\delta_{jk}\delta_{kj}$	em {\color{blue} azul}, cujo valor é 1 quando $j=k$, ou seja, em $n_\ell^2$ ocorrências;
		\item 8 termos do tipo $\delta_{ij}\delta_{jk}\delta_{ki}$ em preto, cujo valor é 1 quando $i=j=k$, ou seja, em $n_\ell$ ocorrências.
	\end{itemize}
\end{frame}

\begin{frame}{Recorrência}
	Assim, (3.36) nos dá a recorrência
	\begin{align*}\tag{3.42}
		G_6^\eellum &=  \frac{C_W^3}{n_\ell^3} \sum_{\mu,\nu,\kappa=1}^{n_\ell} \left(\Wick_6^3 \right) G_6^\eell \\
		&= \frac{C_W^3}{n_\ell^3}\left(n_\ell^3 + 6n_\ell^2 + 8n_\ell\right)G_6^{(\ell)} \\  
		&= C_W^3\left(1 + \frac{6}{n_\ell} + \frac{8}{n_\ell^2}\right)G_6^{(\ell)}
	\end{align*}
\end{frame}

\begin{frame}{Recorrência}
	Descendo até a camada 0, obtemos a relação
	\begin{align*}\tag{3.43}
		G_6^\eell &= \left(C_W^3\right)^{\ell}G_6^{(0)}\prod_{\mi{\ell}=1}^{\ell-1}\left(1 + \frac{6}{n_{\mi\ell}} + \frac{8}{n_{\mi\ell}^2}\right) \\
		& = \left(C_W^3\right)^{\ell}\left(G_2^{(0)}\right)^3\prod_{\mi{\ell}=1}^{\ell-1}\left(1 + \frac{6}{n_{\mi\ell}} + \frac{8}{n_{\mi\ell}^2}\right)\\
		& =  \left(G_2^\eell\right)^3\prod_{\mi{\ell}=1}^{\ell-1}\left(1 + \frac{6}{n_{\mi\ell}} + \frac{8}{n_{\mi\ell}^2}\right)
	\end{align*}
\end{frame}

\begin{frame}{Física: caos}
	Novamente fazendo todos os $n_\ell$ iguais a $n$, obtemos
	\begin{align*}\tag{3.43'}
		G_6^\eell &= \left(G_2^\eell\right)^3\left(1 + \frac{6}{n} + \frac{8}{n^2}\right)^{\ell-1} 
	\end{align*}

	\begin{itemize}
		\item Tomando $n\to\infty$, temos $(1 + 6/n + 8/n^2) \to 1$, e o correlator de 6 pontos converge para a distribuição gaussiana.
		\item Fixando $n$ e fazendo $\ell\to\infty$, o correlator de 6 pontos explode para o infinito, mesmo com a variância $C_W = 1$. 
	\end{itemize}
\end{frame}

\end{document}

