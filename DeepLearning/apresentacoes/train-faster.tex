
\documentclass{beamer}
\usepackage[utf8]{inputenc}
\usepackage[brazil]{babel}
\usepackage{xcolor}
\usepackage{tikz}
\usetikzlibrary{positioning,calc}
\usepackage{graphicx}
\usepackage{cite}
\usepackage{hyperref}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{listings}
\usepackage{enumerate}
\usepackage{fontawesome}
\usepackage{ulem}
\usepackage{xfrac}
\usetheme{mtmufsc} %%%%%%%%Use this template

\usetheme{default}

\newcommand{\EE}{\mathbb{E}}
\title{Train faster, generalize better: Stability of stochastic gradient descent}
\author{Luiz Fernando Bossa}
\date{25 de junho de 2025}

% \newtheorem{theorem}{Teorema}[section]
% \newtheorem{lemma}[theorem]{Lema}
% \newtheorem{definition}[theorem]{Definição}
% \newtheorem{corollary}[theorem]{Corolário}
% \newtheorem{proposition}[theorem]{Proposição}

\begin{document}

\begin{frame}
\titlepage
\end{frame}

\begin{frame}
\frametitle{Sumário}
\tableofcontents
\end{frame}

\section{Introdução}
\begin{frame}
\tableofcontents[currentsection]
\end{frame}

\begin{frame}
\frametitle{Introdução}
\begin{itemize}
    \item O método de otimização mais utilizado na prática de aprendizado de máquina é o método do gradiente estocástico (SGM). 
    \item O SGM visa minimizar o risco empírico de um modelo, calculando repetidamente o gradiente de uma função de perda em um único exemplo de treinamento, ou um lote de poucos exemplos, e atualizando os parâmetros do modelo de acordo. 
    \item Argumentamos que o SGM é algoritmicamente estável no sentido de Bousquet e Elisseeff. 
    \item Nossos resultados estabelecem que: Qualquer modelo treinado com o método do gradiente estocástico em um tempo razoável atinge um pequeno erro de generalização. 
\end{itemize}
\end{frame}

\section{Estabilidade de algoritmos iterativos randomizados}
\begin{frame}
\tableofcontents[currentsection]
\end{frame}

\begin{frame}{Definições gerais}
    \begin{itemize}
        \item Temos uma distribuição de probabilidade \(\mathcal{D}\) sobre um espaço de dados \(Z\).
        \item Temos uma amostra $S = (z_1, \ldots, z_n)$ de tamanho \(n\) extraída i.i.d. de \(\mathcal{D}\).
        \item $\Omega$ o espaço de parâmetros do modelo.
        \item $f$ é a função de perda, $f:\Omega\times Z\rightarrow\mathbb{R}$
    \end{itemize}
\end{frame}


\begin{frame}{Riscos}
    \begin{itemize}
        \item O \emph{risco populacional} é definido como
        \begin{equation*}
            R[w] := \EE_{z\sim\mathcal{D}}[f(w;z)]
        \end{equation*}
        \item O \emph{risco empírico} é definido como a perda média sobre a amostra \(S\):
        \begin{equation*}
            R_{S}[w] := \frac{1}{n}\sum_{i=1}^{n}f(w;z_{i})
        \end{equation*}
    \end{itemize}
\end{frame}

\begin{frame}{Erros}
    \begin{itemize} 
    \item O \emph{erro de generalização} é definido como
         \begin{equation*}
            R_{S}[w] - R[w]
        \end{equation*}
        \item Quando os parâmetros $w$ são dados por um algoritmo $A$ aplicado à amostra $S$, faz sentido definir
        \begin{equation*}
            \epsilon_{gen}  := |R_{S}[A(S)] - R[A(S)]|
        \end{equation*}
    \end{itemize}
\end{frame}

\begin{frame}
\frametitle{Estabilidade Uniforme}
\begin{definition}[2.1]
Um algoritmo randomizado A é \emph{$\epsilon$-uniformemente estável} se para todos os conjuntos de dados S, \(S' \in Z^n\) tal que S e \(S'\) diferem em no máximo uma amostra, temos
\begin{equation*}
    \tag{2.3}
    \sup_{z} \EE_{A}[f(A(S);z) - f(A(S');z)] \le \epsilon 
\end{equation*}
\end{definition}
\small
\begin{itemize}
    \item A esperança é tomada apenas sobre a aleatoriedade interna de A.
    \item Denotamos por $\epsilon_{stab}(A,n)$ o ínfimo sobre todos os $\epsilon$ para os quais (2.3) é válido.
    \item Omitiremos $(A,n)$ quando o contexto for claro.
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Generalização na Expectativa}
\begin{theorem}[2.2] Seja A \(\epsilon\)-uniformemente estável. Então,
$$ |\EE_{S,A}[R_{S}[A(S)] - R[A(S)]]| \le \epsilon $$ 
\end{theorem}
\end{frame}

\begin{frame}{Demonstração do Teorema 2.2} 
\(S=(z_{1},\ldots,z_{n})\) e \(S'=(z'_{1},\ldots,z'_{n})\) duas amostras aleatórias independentes. 
Seja \(S^{(i)}=(z_{1},\ldots,z_{i-1},z'_{i},z_{i+1},\ldots,z_{n})\)  
\begin{align*}
\EE_{S}\EE_{A}[R_{S}[A(S)]] &= \EE_{S}\EE_{A}[\frac{1}{n}\sum_{i=1}^{n}f(A(S);z_{i})] \\
&= \EE_{S}\EE_{S'}\EE_{A}[\frac{1}{n}\sum_{i=1}^{n}f(A(S^{(i)});z'_{i})] \\
&= \EE_{S}\EE_{S'}\EE_{A}[\frac{1}{n}\sum_{i=1}^{n}f(A(S);z'_{i})] + \delta \\
&= \EE_{S}\EE_{A}[R[A(S)]] + \delta
\end{align*}
\end{frame}

\begin{frame}{Demonstração do Teorema 2.2} 
    onde podemos expressar \(\delta\) como
$$ \delta = \EE_{S}\EE_{S'}\EE_{A}[\frac{1}{n}\sum_{i=1}^{n}f(A(S^{(i)});z'_{i}) - \frac{1}{n}\sum_{i=1}^{n}f(A(S);z'_{i})] $$
Além disso, tomando o supremo sobre quaisquer dois conjuntos de dados S, \(S'\) diferindo em apenas uma amostra, podemos limitar a diferença como
$$ |\delta| \le \sup_{S,S',z}\EE_{A}[f(A(S);z) - f(A(S');z)] \le \epsilon, $$
pela nossa suposição sobre a estabilidade uniforme de A. A afirmação segue.  
\end{frame}

\begin{frame}
\frametitle{Regras de Atualização}
\begin{definition}[2.3]
Uma regra de atualização é \(\eta\)-expansiva se
$$ \sup_{v,w \in \Omega} \frac{\|G(v) - G(w)\|}{\|v - w\|} \le \eta. $$ 
\end{definition}

\begin{definition}[2.4]
Uma regra de atualização é \(\sigma\)-limitada se
$$ \sup_{w \in \Omega} \|w - G(w)\| \le \sigma. $$ 
\end{definition}
\end{frame}
 

\begin{frame}
\frametitle{Recursão de Crescimento}
\begin{lemma}[2.5] Fixe uma sequência arbitrária de atualizações \(G_{1},\ldots,G_{T}\) e outra sequência \(G'_{1},\ldots,G'_{T}\). Seja \(w_{0}=w'_{0}\) um ponto de partida em \(\Omega\) e defina \(\delta_{t}=\|w'_{t}-w_{t}\|\) onde \(w_{t}\) e \(w'_{t}\) são definidos recursivamente através de 
\[w_{t+1}=G_{t+1}(w_{t}), \qquad  w'_{t+1}=G'_{t+1}(w'_{t}), \quad t\ge0\]
Então, temos a relação de recorrência: 
\small
\begin{align*}
     \delta_{0}&=0 \\
     \delta_{t+1} &\le \begin{cases} \eta\delta_{t} & G_{t}=G'_{t} \text{ é } \eta\text{-expansiva} \\ \min(\eta,1)\delta_{t}+2\sigma & G_{t} \text{ e } G'_{t} \text{ são } \sigma\text{-limitadas, } G_{t} \text{ é } \eta\text{-expan.} \end{cases}
\end{align*} 
\end{lemma}
\end{frame}

\begin{frame}{Demonstração}
O primeiro limite em \(\delta_{t}\) segue diretamente da suposição de que \(G_{t}=G'_{t}\) e da definição de $\eta$-expansividade.  
Para o segundo limite, vamos usar a desigualdade triangular e truque de soma zero:
{\small
$$ \delta_{t+1} = \|G(w_{t}) - G'(w'_{t})\| \le \|G(w_{t})-w_{t}+w'_{t}-G'(w'_{t})\| + \|w_{t}-w'_{t}\| $$
$$ \le \delta_{t} + \|G(w_{t})-w_{t}\| + \|G'(w'_{t})-w'_{t}\| \le \delta_{t} + 2\sigma $$
}
Alternativamente, podemos limitar \(\delta_{t+1}\) como
\small
\begin{align*}
\delta_{t+1} &= \|G_{t}(w_{t})-G'_{t}(w'_{t})\| \\
&= \|G_{t}(w_{t})-G_{t}(w'_{t})+G_{t}(w'_{t})-G'_{t}(w'_{t})\| \\
&\le \|G_{t}(w_{t})-G_{t}(w'_{t})\| + \|G_{t}(w'_{t})-G'_{t}(w'_{t})\| \\
&\le \eta\delta_{t} + 2\sigma.
\end{align*} 
\end{frame}

\section{Estabilidade do Método do Gradiente Estocástico}
\begin{frame}
\tableofcontents[currentsection]
\end{frame}

\begin{frame}
\frametitle{Regra de Atualização do Gradiente}
\begin{definition}[3.1]
Para um tamanho de passo não negativo \(\alpha > 0\) e uma função \(f:\Omega \rightarrow \mathbb{R}\), definimos a regra de atualização do gradiente \(G_{f,\alpha}\) como
$$ G_{f,\alpha}(w) = w - \alpha\nabla f(w). $$ 
\end{definition}
\end{frame}

\begin{frame}
\frametitle{Definições}
\begin{definition}[3.2]
Dizemos que $f$ é $L$-Lipschitz se para todos os pontos $u$ no domínio de $f$ temos \(\|\nabla f(x)\| \le L\). Isso implica que
$$ |f(u) - f(v)| \le L\|u-v\|. $$ 
\end{definition}
\begin{lemma}[3.3]
Assuma que f é L-Lipschitz. Então, a atualização de gradiente \(G_{f,\alpha}\) é \((\alpha L)\)-limitada. 
\end{lemma} 
\end{frame}
 

\begin{frame}{Definições}
\begin{definition}[3.4]
Uma função \(f:\Omega \rightarrow \mathbb{R}\) é convexa se para todo \(u, v \in \Omega\) temos
$$ f(u) \ge f(v) + \langle\nabla f(v), u-v\rangle. $$
\end{definition} 
  
\begin{definition}[3.5]
Uma função \(f:\Omega \rightarrow \mathbb{R}\) é \(\gamma\)-fortemente convexa se para todo \(u, v \in \Omega\) temos
$$ f(u) \ge f(v) + \langle\nabla f(v), u-v\rangle + \frac{\gamma}{2}\|u-v\|^2. $$
\end{definition}
\end{frame}
\begin{frame}{Definições}
\begin{definition}[3.6]
Uma função \(f:\Omega \rightarrow \mathbb{R}\) é \(\beta\)-suave se para todo \(u, v \in \Omega\) temos
$$ \|\nabla f(u) - \nabla f(v)\| \le \beta\|u-v\|. $$ 
\end{definition}
\end{frame}


\begin{frame}
\frametitle{Lema 3.7}
\begin{lemma}[3.7]
Assuma que f é \(\beta\)-suave. Então, as seguintes propriedades são válidas: 
\begin{enumerate}
    \item \(G_{f,\alpha}\) é \((1+\alpha\beta)\)-expansiva. 
    \item Assuma adicionalmente que f é convexa. Então, para qualquer \(\alpha \le 2/\beta\), a atualização de gradiente \(G_{f,\alpha}\) é 1-expansiva.
    \item Assuma adicionalmente que f é \(\gamma\)-fortemente convexa. Então, para \(\alpha \le \frac{2}{\beta+\gamma}\), \(G_{f,\alpha}\) é \(\left(1-\frac{\alpha\beta\gamma}{\beta+\gamma}\right)\)-expansiva.
\end{enumerate}
\end{lemma}
\end{frame}

\begin{frame}
\frametitle{Teorema 3.8: Otimização Convexa}
\begin{theorem}[3.8]
Assuma que a função de perda \(f(\cdot;z)\) é \(\beta\)-suave, convexa e L-Lipschitz para todo z.  Suponha que executamos SGM com tamanhos de passo \(\alpha_{t} \le 2/\beta\) por T passos. Então, SGM satisfaz estabilidade uniforme com
$$ \epsilon_{stab} \le \frac{2L^2}{n}\sum_{t=1}^{T}\alpha_{t}. $$ 
\end{theorem}
\end{frame}

\begin{frame}{Demonstração do Teorema 3.8} 
Sejam $S$ e \(S'\) duas amostras de tamanho $n$ diferindo em uma única amostra, $\{G_i\}_{i=1}^{T}$ e $\{G_i^\prime\}_{i=1}^{T}$ as atualizações de gradiente estocástico correspondentes, $w_T$ e $w'_T$ os parâmetros finais correspondentes.



\begin{itemize}
    \item Aplica Lipschitz em \(f(\cdot;z)\):
    \begin{equation*}        \tag{3.3}
        \EE|f(w_{T};z) - f(w'_{T};z)| \le L\EE[\|w_{T} - w'_{T}\|] = L\EE[\delta_{T}]
    \end{equation*}
\end{itemize}

\end{frame}
\begin{frame}{Demonstração do Teorema 3.8}
    
\begin{itemize} 
    \item Com probabilidade $1-\frac{1}{n}$, temos que $G_t$ e $G'_t$ são idênticas, e nossas hipóteses permitem aplicar o Lema 3.7(2) para concluir que \(G_{f,\alpha}\) é 1-expansiva.
    \item Com probabilidade $\frac{1}{n}$, a amostra escolhida é diferente, e usamos que $G_t$ e $G_t^\prime$ são $\alpha_tL$-limitadas (Lema 3.3);
\end{itemize}
\begin{align*}\tag{3.4}
    \EE[\delta_{t+1}] &\le \left(1-\frac{1}{n}\right)\EE[\eta\delta_{t}] + \frac{1}{n}\EE[\eta\delta_{t} + 2\alpha_t L] \\
    &= \left(1-\frac{1}{n}\right)\EE[\delta_{t}] + \frac{1}{n}\EE[\delta_{t}] + \frac{2\alpha_t L}{n} \\
    &= \EE[\delta_{t}] + \frac{2\alpha_t L}{n}
\end{align*}
\end{frame}

\begin{frame}{Demonstração do Teorema 3.8}
    \begin{itemize}
        \item Desenrolando essa recursão, e lembrando que $\delta_0=0$, obtemos
$$ \EE[\delta_{T}] \le \sum_{t=1}^{T} \frac{2\alpha_t L}{n} = \frac{2L}{n}\sum_{t=1}^{T}\alpha_t $$
\item Voltando para (3.3), temos
 $$ \EE|f(w_{T};z) - f(w'_{T};z)| \le L\EE[\delta_{T}] \le \frac{2L^2}{n}\sum_{t=1}^{T}\alpha_{t} $$
 \item Como $\epsilon_{stab} $ é o mínimo dentre os valores possíveis, segue o resultado.
    \end{itemize}
\end{frame}

\begin{frame}
\frametitle{Teorema 3.9: Otimização Fortemente Convexa}
\begin{theorem}[3.9]
Assuma que a função de perda \(f(\cdot;z)\) é \(\gamma\)-fortemente convexa e \(\beta\)-suave para todo z.  Então, SGM satisfaz estabilidade uniforme com
$$ \epsilon_{stab} \le \frac{2L^2}{\gamma n}. $$ 
\end{theorem}
\end{frame}

\begin{frame}
\frametitle{Demonstração do Teorema 3.9}
\begin{proof}
A demonstração é análoga à do Teorema 3.8.  Com probabilidade \(1/n\), o exemplo é diferente. A recorrência para \(\EE\delta_{t+1}\) é:
$$ \EE\delta_{t+1} \le (1-\frac{1}{n})(1-\alpha\gamma)\EE\delta_{t} + \frac{1}{n}((1-\alpha\gamma)\EE\delta_{t} + 2\alpha L) $$ 
$$ = (1-\alpha\gamma)\EE\delta_{t} + \frac{2\alpha L}{n} $$ 
Desdobrando a recursão:
$$ \EE\delta_{T} \le \frac{2L\alpha}{n}\sum_{t=0}^{T}(1-\alpha\gamma)^{t} \le \frac{2L}{\gamma n}. $$ 
O resultado segue aplicando a condição de Lipschitz. 
\end{proof}
\end{frame}

\begin{frame}
\frametitle{Teorema 3.10}
\begin{theorem}
Assuma que a função de perda \(f(\cdot;z) \in [0,1]\) é \(\gamma\)-fortemente convexa, tem gradientes limitados por L, e é \(\beta\)-suave para todo z.  Suponha que executamos SGM com tamanhos de passo \(\alpha_{t} = \frac{1}{\gamma t}\). Então, SGM tem estabilidade uniforme de
$$ \epsilon_{stab} \le \frac{2L^2 + \beta\rho}{\gamma n} $$
onde \(\rho = \sup_{w\in\Omega}\sup_{z}f(w;z)\). 
\end{theorem}
\end{frame}

\begin{frame}
\frametitle{Demonstração do Teorema 3.10}
\begin{proof}
Quando \(t > \frac{\beta}{\gamma}\), as iterações são contrativas. Para \(t \ge t_0 := \frac{\beta}{\gamma}\):
$$ \EE[\delta_{t+1}] \le (1-\alpha_t\gamma)\EE[\delta_t] + \frac{2\alpha_t L}{n} = (1-\frac{1}{t})\EE[\delta_t] + \frac{2L}{\gamma tn} $$ 
Assumindo \(\delta_{t_0}=0\) e expandindo a recursão:
$$ \EE[\delta_T] \le \sum_{t=t_0}^{T} \left\{ \prod_{s=t+1}^{T} (1-\frac{1}{s}) \right\} \frac{2L}{\gamma tn} = \sum_{t=t_0}^{T} \frac{t}{T} \frac{2L}{\gamma tn} = \frac{T-t_0+1}{T} \cdot \frac{2L}{\gamma n} $$
O resultado segue do Lema 3.11 com o fato de que \(t_0 = \frac{\beta}{\gamma}\).
\end{proof}
\end{frame}

\begin{frame}
\frametitle{Lema 3.11: Otimização Não-Convexa}
\begin{lemma}
Assuma que a função de perda \(f(\cdot;z)\) é não negativa e L-Lipschitz para todo z.  Então, para todo \(z \in Z\) e todo \(t_0 \in \{0,1,\ldots,n\}\), temos
$$ \EE|f(w_T;z) - f(w'_T;z)| \le \frac{t_0}{n}\sup_{w,z}f(w;z) + L\EE[\delta_T|\delta_{t_0}=0]. $$ 
\end{lemma}
\end{frame}

\begin{frame}
\frametitle{Demonstração do Lema 3.11}
\begin{proof}
Seja \(\mathcal{E} = 1[\delta_{t_0}=0]\) o evento que \(\delta_{t_0}=0\). Temos:
\begin{align*}
\EE|f(w_T;z) - f(w'_T;z)| &= \mathbb{P}\{\mathcal{E}\}\EE[|f(w_T;z) - f(w'_T;z)\|\mathcal{E}] + \mathbb{P}\{\mathcal{E}^c\}\EE[|f(w_T;z) - f(w'_T;z)\|\mathcal{E}^c] \\
&\le \EE[|f(w_T;z) - f(w'_T;z)\|\mathcal{E}] + \mathbb{P}\{\mathcal{E}^c\} \cdot \sup_{w,z}f(w;z) \\
&\le L\EE[\|w_T - w'_T\\|\mathcal{E}] + \mathbb{P}\{\mathcal{E}^c\} \cdot \sup_{w,z}f(w;z).
\end{align*} 
Resta limitar \(\mathbb{P}\{\mathcal{E}^c\}\). Seja I o índice do primeiro passo de tempo em que SGM usa o exemplo diferente. Note que quando \(I > t_0\), então \(\delta_{t_0}=0\). 
\end{proof}
\end{frame}

\begin{frame}
\frametitle{Teorema 3.12}
\begin{theorem}
Assuma que \(f(\cdot;z) \in [0,1]\) é uma função de perda L-Lipschitz e \(\beta\)-suave para todo z.  Então, SGM tem estabilidade uniforme com
$$ \epsilon_{stab} \le \frac{1+1/\beta c}{n-1}(2cL^2)^{\frac{1}{\beta c+1}}T^{\frac{\beta c}{\beta c+1}} $$ 
Em particular, omitindo fatores constantes, obtemos
$$ \epsilon_{stab} \le \frac{T^{1-1/(\beta c+1)}}{n} $$ 
\end{theorem}
\end{frame}

\begin{frame}
\frametitle{Demonstração do Teorema 3.12}
\begin{proof}
Pelo Lema 3.11, para todo \(t_0 \in \{1,\ldots,n\}\):
$$ \EE|f(w_T;z) - f(w'_T;z)| \le \frac{t_0}{n} + L\EE[\delta_T|\delta_{t_0}=0] $$ 
Seja \(\Delta_t = \EE[\delta_t|\delta_{t_0}=0]\). Para \(t \ge t_0\):
$$ \Delta_{t+1} \le (1-\frac{1}{n})(1+\alpha_t\beta)\Delta_t + \frac{2\alpha_t L}{n} \le \exp((1-1/n)\frac{c\beta}{t})\Delta_t + \frac{2cL}{tn} $$ 
Desdobrando a recorrência e usando \(\Delta_{t_0}=0\):
$$ \Delta_T \le \sum_{t=t_0+1}^{T} \exp((1-\frac{1}{n})\beta c \log(\frac{T}{t})) \frac{2cL}{tn} = \frac{2cL}{n} T^{\beta c(1-1/n)} \sum_{t=t_0+1}^{T} t^{-\beta c(1-1/n)-1} $$ 
$$ \le \frac{2L}{\beta(n-1)}(\frac{T}{t_0})^{\beta c} $$ 
Minimizando a expressão para \(\EE|f(w_T;z) - f(w'_T;z)|\) em relação a \(t_0\), obtemos o resultado. 
\end{proof}
\end{frame}


\section{Operações que induzem estabilidade}
\begin{frame}
\tableofcontents[currentsection]
\end{frame}

\begin{frame}
\frametitle{Definição 4.1: Decaimento de Peso}
\begin{definition}
Seja \(f:\Omega \rightarrow \Omega\) uma função diferenciável. Definimos a atualização de gradiente com decaimento de peso na taxa \(\mu\) como
$$ G_{f,\mu,\alpha}(w) = (1-\alpha\mu)w - \alpha\nabla f(w). $$ 
\end{definition}
\end{frame}

\begin{frame}
\frametitle{Lema 4.2}
\begin{lemma}
Assuma que f é \(\beta\)-suave. Então, \(G_{f,\mu,\alpha}\) é \((1+\alpha(\beta-\mu))\)-expansiva. 
\end{lemma}
\end{frame}

\begin{frame}
\frametitle{Demonstração do Lema 4.2}
\begin{proof}
Seja \(G = G_{f,\mu,\alpha}\). Pela desigualdade triangular e nossa suposição de suavidade,
\begin{align*}
\|G(v) - G(w)\| &\le (1-\alpha\mu)\|v-w\| + \alpha\|\nabla f(w) - \nabla f(v)\| \\
&\le (1-\alpha\mu)\|v-w\| + \alpha\beta\|w-v\| \\
&= (1-\alpha\mu+\alpha\beta)\|v-w\|.
\end{align*} 
\end{proof}
\end{frame}

\begin{frame}
\frametitle{Definição 4.3: Operador de Dropout}
\begin{definition}
Dizemos que um mapa randomizado \(D:\Omega \rightarrow \Omega\) é um operador de dropout com taxa de dropout s se para cada \(v \in D\) temos \(\EE\|Dv\| = s\|v\|\). 
\end{definition}
\end{frame}

\begin{frame}
\frametitle{Lema 4.4}
\begin{lemma}
Assuma que f é L-Lipschitz. Então, a atualização de dropout \(DG_{f,\alpha}\) com taxa de dropout s é \((\alpha s L)\)-limitada. 
\end{lemma}
\end{frame}

\begin{frame}
\frametitle{Demonstração do Lema 4.4}
\begin{proof}
Pela nossa suposição de Lipschitz e linearidade da expectativa,
$$ \EE\|G_{f,\alpha}(v) - v\| = \alpha\EE\|D\nabla f(v)\| = \alpha s\EE\|\nabla f(v)\| \le \alpha s L. $$ 
\end{proof}
\end{frame}

\begin{frame}
\frametitle{Definição 4.5: Regra de Atualização Proximal}
\begin{definition}
Para um tamanho de passo não negativo \(\alpha \ge 0\) e uma função \(f:\Omega \rightarrow \mathbb{R}\), definimos a regra de atualização proximal \(P_{f,\alpha}\) como
$$ P_{f,\alpha}(w) = \arg\min_{v} \frac{1}{2}\|w-v\|^2 + \alpha f(v). $$ 
\end{definition}
\end{frame}

\begin{frame}
\frametitle{Lema 4.6}
\begin{lemma}
Se f é convexa, a atualização proximal (4.1) é 1-expansiva. 
\end{lemma}
\end{frame}

\begin{frame}
\frametitle{Demonstração do Lema 4.6}
\begin{proof}
Defina \(P_{\nu}(w) = \arg\min_v \frac{1}{2\nu}\|w-v\|^2 + f(v)\).  Usando esta desigualdade, temos
\begin{align*}
\|v-w\|^2 &= \|[P_{\nu}(v)-P_{\nu}(w)] + [Q_{\nu}(v)-Q_{\nu}(w)]\|^2 \\
&= \|P_{\nu}(v)-P_{\nu}(w)\|^2 + 2\langle P_{\nu}(v)-P_{\nu}(w),Q_{\nu}(v)-Q_{\nu}(w)\rangle + \|Q_{\nu}(v)-Q_{\nu}(w)\|^2 \\
&\ge \|P_{\nu}(v)-P_{\nu}(w)\|^2
\end{align*}
completando assim a demonstração. 
\end{proof}
\end{frame}

\begin{frame}
\frametitle{Teorema 4.7: Média de Modelos}
\begin{theorem}
Assuma que \(f:\Omega \rightarrow [0,1]\) é uma função convexa, L-Lipschitz e \(\beta\)-suave decomponível e que executamos SGD com tamanhos de passo \(\alpha_t \le \alpha \le 2/\beta\) por T passos. 
\end{theorem}
\end{frame}

\begin{frame}
\frametitle{Demonstração do Teorema 4.7}
\begin{proof}
Seja \(\bar{w}_T = \frac{1}{T}\sum_{t=1}^T w_t\) a média das iterações do gradiente estocástico.  Usando o Lema 3.8, o desvio entre \(\bar{w}_t\) e \(\bar{w}'_t\) obedece
$$ \delta_t \le (1-1/n)\delta_{t-1} + \frac{1}{n}(\delta_{t-1} + 2\alpha L \frac{T-t+1}{T}) $$ 
o que implica
$$ \delta_T \le \frac{2\alpha L}{n} \sum_{t=1}^T \frac{T-t+1}{T} = \frac{\alpha L(T+1)}{n}. $$ 
Como f é L-Lipschitz, temos
$$ \EE|f(\bar{w}_T) - f(\bar{w}'_T)| \le L\|\bar{w}_T - \bar{w}'_T\| \le \frac{\alpha(T+1)L^2}{n}. $$ 
A afirmação segue pela nossa definição de estabilidade uniforme.
\end{proof}
\end{frame}

\section{Minimização de Risco Convexo}
\begin{frame}
\tableofcontents[currentsection]
\end{frame}

\begin{frame}
\frametitle{Lema 5.1}
\begin{lemma}
Seja \(w_*\) o minimizador do risco da população e \(w_*^S\) o minimizador do risco empírico dado um conjunto de dados amostrado S. Então \(\EE[R_S[w_*^S]] \le R[w_*]\). 
\end{lemma}
\end{frame}

\begin{frame}
\frametitle{Demonstração do Lema 5.1}
\begin{proof}
\begin{align*}
R[w_*] &= \inf_w R[w] = \inf_w \EE_z[f(w;z)] \\
&= \inf_w \EE_S[\frac{1}{n}\sum_{i=1}^n f(w;z_i)] \\
&\ge \EE_S[\inf_w \frac{1}{n}\sum_{i=1}^n f(w;z_i)] \quad \text{(pela desigualdade de Jensen)} \\
&= \EE_S[\frac{1}{n}\sum_{i=1}^n f(w_*^S;z_i)] = \EE[R_S[w_*^S]].
\end{align*} 
\end{proof}
\end{frame}

\begin{frame}
\frametitle{Teorema 5.2 (Nemirovski e Yudin)}
\begin{theorem}
Assuma que executamos o gradiente estocástico descendente com tamanho de passo constante \(\alpha\) em uma função convexa \(R[w]=\EE_z[f(w;z)]\).  Então temos
$$ R[\bar{w}_T] \le R[w_*] + \frac{1}{2}\frac{D^2}{T\alpha} + \frac{1}{2}L^2\alpha. $$ 
\end{theorem}
\end{frame}

\begin{frame}
\frametitle{Corolário 5.3}
\begin{block}{Corolário 5.3}
Seja f uma função de perda convexa satisfazendo \(\|\nabla f(w,z)\| \le L\) e seja \(w_*\) um minimizador do risco da população \(R[w] = \EE_z f(w;z)\).  Então, a média \(\bar{w}_n\) das iterações satisfaz
$$ \EE[R[\bar{w}_n]] \le R[w_*] + \frac{DL}{\sqrt{n}}. $$ 
\end{block}
\end{frame}

\begin{frame}
\frametitle{Proposição 5.4}
\begin{block}{Proposição 5.4}
Seja S uma amostra de tamanho n. Seja f uma função de perda convexa \(\beta\)-suave satisfazendo \(\|\nabla f(w,z)\| \le L\) e seja \(w_*^S\) um minimizador do risco empírico.  Então, a média \(\bar{w}_T\) sobre as iterações satisfaz
$$ \EE[R[\bar{w}_T]] \le \EE[R_S[w_*^S]] + \frac{DL}{\sqrt{n}}\sqrt{\frac{n+2T}{T}}. $$ 
\end{block}
\end{frame}

\begin{frame}
\frametitle{Demonstração da Proposição 5.4}
\begin{proof}
Aplicando o Teorema 5.2 ao risco empírico \(R_S\), obtemos o erro de otimização \(\epsilon_{opt}(\bar{w}_T) \le \frac{1}{2}\frac{D^2}{T\alpha} + \frac{1}{2}L^2\alpha\).  Combinando as duas desigualdades:
$$ \EE[R[\bar{w}_T]] \le \EE[R_S[w_*^S]] + \frac{1}{2}\frac{D^2}{T\alpha} + \frac{1}{2}L^2(1+\frac{2T}{n})\alpha. $$ 
Escolhendo \(\alpha = \frac{D\sqrt{n}}{L\sqrt{T(n+2T)}}\) resulta no limite fornecido na proposição. 
\end{proof}
\end{frame}


\end{document}
