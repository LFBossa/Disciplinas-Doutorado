# Princípios de Aprendizagem Profunda

Livro texto: [The Principles of Deep Learning Theory](https://arxiv.org/abs/2106.10165) (Daniel A. Roberts, Sho Yaida, Boris Hanin)

[Elementos da Teoria de Aprendizagem de Máquina Supervisionada - Vladimir G. Pestov](https://impa.br/wp-content/uploads/2022/03/32CBM07_eBook.pdf)



# Distribuições multivariadas

- Matriz de covariância
	- porque é simétrica e definida positiva?
	
- Funções densidade
- Distribuição marginal

[Slides - Distribuições Multivariadas](./apresentacoes/slides-multivariadas.pdf)

## Referências

- [Estatística Multivariada | UFPR](http://leg.ufpr.br/~lucambio/MSM/MSM0.html)
- [ME731 - Métodos em Análise Multivariada | Unicamp](https://www.ime.unicamp.br/~cnaber/Material_AM_ME731_2S_2021.htm)
- [Métodos em Análise Multivariada 2022.2](https://www.ime.unicamp.br/~ctrucios/ME_731.html)
- [Amostragem multivariada](http://ftp.demec.ufpr.br/disciplinas/TM788/Daniel%20Furtado%20Ferreira/Capitulo%203.pdf)

# Teorema de Cybenko (1989)


- [CS229T/STAT231: Statistical Learning Theory (Winter 2016) - Percy Liang](https://web.stanford.edu/class/cs229t/notes.pdf)
- [Telgarsky, 2012: Representation Power of Feedforward Neural Networks (slides)](https://cseweb.ucsd.edu/~dasgupta/254-deep/matus.pdf)
- [CSE 254: Seminar on Learning Algorithms](https://cseweb.ucsd.edu/~dasgupta/254-deep/)
- [Sanjoy Dasgupta - Teaching](https://cseweb.ucsd.edu/~dasgupta/courses.html)
- [Andoni/Panigrahy/Valiant/Zhang, 2014: Learning Polynomials with Neural Networks](https://theory.stanford.edu/~valiant/papers/andoni14.pdf)
- [Schmidhuber, 2014: Deep Learning in Neural Networks: An Overview](https://arxiv.org/pdf/1404.7828v4)
- [University of Cambridge -  Teaching - Mathematics of Machine Learning](https://www.statslab.cam.ac.uk/~rds37/machine_learning.html)
- [Cybenko’s Theorem and the capability of a neural network as function approximator](https://www.mathematik.uni-wuerzburg.de/fileadmin/10040900/2019/Seminar__Artificial_Neural_Network__24_9__.pdf)
- [Introduction to Online Convex Optimization](https://arxiv.org/pdf/1909.05207)
- [ECE 598MR: Statistical Learning Theory (Fall 2014)](https://maxim.ece.illinois.edu/teaching/fall14/schedule.html)
- [Sasha Rakhlin - Professor @ MIT | Statistics and Data Science Center, IDSS](https://www.mit.edu/~rakhlin/)
- [Benign overfitting in overparametrized models](https://www.cambridge.org/core/services/aop-cambridge-core/content/view/7BCB89D860CEDDD5726088FAD64F2A5A/S0962492921000027a.pdf/deep-learning-a-statistical-viewpoint.pdf)
- [Mathematics of Machine Learning](https://ocw.mit.edu/courses/18-657-mathematics-of-machine-learning-fall-2015/pages/readings/)

# Neural Nets

- [Neural Nets from Scratch in Julia [PART 1]: Introduction](https://www.youtube.com/watch?v=Kybn21KA96g)

1) Artigo de Lin, Tegmark e Rolnik [“Why does deep and cheap learning work so well?”](https://arxiv.org/abs/1608.08225)
2) Artigo de Tegmark e Rolnick [“The power of deeper networks for expressing natural functions”](https://arxiv.org/abs/1705.05502)